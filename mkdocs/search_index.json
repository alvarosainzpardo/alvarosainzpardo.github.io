{
    "docs": [
        {
            "location": "/",
            "text": "Documentaci\u00f3n de Alvaro Sainz-Pardo.\n\n\nDocumentaci\u00f3n y apuntes sobre temas diversos, relacionados con mi trabajo o con intereses personales, fundamentalmente herramientas de desarrollo y lenguajes de programaci\u00f3n.\n\n\nEste sitio web est\u00e1 hecho con MkDocs. Para m\u00e1s informaci\u00f3n, visitar \nmkdocs.org\n.\n\n\n\n\nGuia de MkDocs\n\n\nEsta documentaci\u00f3n la mantengo en Github Pages, en el repositorio correspondiente al Github Pages de mi cuenta, o sea el repositorio alvarosainzpardo.github.io. En este repositorio tengo dos ramas (branches). La rama \nmaster\n es la que gestiona MkDocs. Los archivos fuente de la documentaci\u00f3n los tengo en la rama \ndocs\n.\n\n\nComandos principales de MkDocs\n\n\n\n\nmkdocs gh-deploy --clean\n - Desplegar/Actualizar la documentaci\u00f3n MkDocs en Github.\n\n\n\n\nOtros comandos\n\n\n\n\nmkdocs new [dir-name]\n - Create a new project.\n\n\nmkdocs serve\n - Start the live-reloading docs server.\n\n\nmkdocs build\n - Build the documentation site.\n\n\nmkdocs help\n - Print this help message.\n\n\n\n\nEstructura del proyecto\n\n\nmkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.",
            "title": "Home"
        },
        {
            "location": "/#documentacion-de-alvaro-sainz-pardo",
            "text": "Documentaci\u00f3n y apuntes sobre temas diversos, relacionados con mi trabajo o con intereses personales, fundamentalmente herramientas de desarrollo y lenguajes de programaci\u00f3n.  Este sitio web est\u00e1 hecho con MkDocs. Para m\u00e1s informaci\u00f3n, visitar  mkdocs.org .",
            "title": "Documentaci\u00f3n de Alvaro Sainz-Pardo."
        },
        {
            "location": "/#guia-de-mkdocs",
            "text": "Esta documentaci\u00f3n la mantengo en Github Pages, en el repositorio correspondiente al Github Pages de mi cuenta, o sea el repositorio alvarosainzpardo.github.io. En este repositorio tengo dos ramas (branches). La rama  master  es la que gestiona MkDocs. Los archivos fuente de la documentaci\u00f3n los tengo en la rama  docs .",
            "title": "Guia de MkDocs"
        },
        {
            "location": "/#comandos-principales-de-mkdocs",
            "text": "mkdocs gh-deploy --clean  - Desplegar/Actualizar la documentaci\u00f3n MkDocs en Github.",
            "title": "Comandos principales de MkDocs"
        },
        {
            "location": "/#otros-comandos",
            "text": "mkdocs new [dir-name]  - Create a new project.  mkdocs serve  - Start the live-reloading docs server.  mkdocs build  - Build the documentation site.  mkdocs help  - Print this help message.",
            "title": "Otros comandos"
        },
        {
            "location": "/#estructura-del-proyecto",
            "text": "mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.",
            "title": "Estructura del proyecto"
        },
        {
            "location": "/smart_cities/",
            "text": "Smart Cities\n\n\n\n\nEnlaces, documentaci\u00f3n, recursos\n\n\n\n\nNoticias\n\n\nCentro\n\n\nSur\n\n\n\n\n(20/12/2017) \nM\u00e1laga sustituir\u00e1 m\u00e1s de 6.000 puntos de luz por tecnolog\u00eda LED\n: El Ayuntamiento de M\u00e1laga, a trav\u00e9s del \u00e1rea de Servicios Operativos, renovar\u00e1 gracias a su Plan \u2018M\u00e1s barrios, m\u00e1s M\u00e1laga\u2019 de Inversiones Financieramente Sostenibles m\u00e1s de 6.000 puntos de luz en 1.223 calles de la ciudad para abaratar el consumo el\u00e9ctrico y mejorar la calidad del alumbrado. De esta manera se va ampliando paulatinamente a toda la ciudad la instalaci\u00f3n de tecnolog\u00eda led. En estos momentos la capital cuenta con un 10% de farolas con tecnolog\u00eda led y con la ejecuci\u00f3n de este nuevo contrato se pasar\u00e1 a un 20% de los 64.000 puntos de luz que hay en M\u00e1laga. En concreto, en 2018 se beneficiar\u00e1n de esta renovaci\u00f3n los distritos de Bail\u00e9n Miraflores, Ciudad Jard\u00edn y Palma-Palmilla.\n\n\n(19/12/2017) \nAndaluc\u00eda crea una plataforma Smart Data para conocer mejor al visitante y optimizar sus destinos tur\u00edsticos\n: Andaluc\u00eda cuenta con una herramienta para el turismo en la comunidad con el primer Smart Data regional y p\u00fablico, que permitir\u00e1 a destinos y empresas perfeccionar la experiencia del cliente, conocer mejor el mercado al que se dirigen, optimizar las acciones promocionales y de planificaci\u00f3n en funci\u00f3n del inter\u00e9s y el grado de satisfacci\u00f3n del viajero y programar las campa\u00f1as tur\u00edsticas.\n\n\n(18/12/2017) \nEl Parlamento de Andaluc\u00eda aprueba la Ley de Participaci\u00f3n Ciudadana de la Comunidad Aut\u00f3noma\n: El Pleno del Parlamento de Andaluc\u00eda ha aprobado la Ley de Participaci\u00f3n Ciudadana de Andaluc\u00eda, que impulsar\u00e1 en la comunidad aut\u00f3noma nuevas formas de democracia directa complementarias del modelo representativo. El texto regula la ampliaci\u00f3n del derecho de participaci\u00f3n y de las f\u00f3rmulas de gobierno abierto y transparencia ya recogidas en el Estatuto de Autonom\u00eda, posibilitando su ejercicio dentro de los l\u00edmites del actual marco legislativo y haci\u00e9ndolo extensible a los mayores de 16 a\u00f1os con vecindad en Andaluc\u00eda.\n\n\n\n\nEste\n\n\n\n\n(14/12/2017) \nValencia instalar\u00e1 3.000 luminarias con telegesti\u00f3n punto a punto\n: Los distritos de la zona Norte de Valencia contar\u00e1n con nuevas luminarias equipadas con dispositivos de telegesti\u00f3n punto a punto con comunicaci\u00f3n bidireccional, lo que permite a los gestores en los centros de mandos conocer, de manera remota, tanto la evoluci\u00f3n del consumo en cada momento, como las posibles aver\u00edas del sistema en tiempo real.\n\n\n(14/12/2017) \nMurcia participa junto a ciudades de Jap\u00f3n en el desarrollo de una plataforma abierta de Ciudad Inteligente\n: Murcia es la \u00fanica ciudad espa\u00f1ola que desarrolla junto con Tokio, Sapporo, Yokosuku, \u00c1msterdam y Zurich una plataforma abierta que sirva de base para una infraestructura de datos de ciudad inteligente.\n\n\n\n\nNorte\n\n\n\n\n(19/12/2017)\nRuta Smart Ribera del Duero: se\u00f1alizaci\u00f3n tur\u00edstica inteligente conectada con Inventrip\n: \nSismotur\n ha creado una red global de se\u00f1alizaci\u00f3n tur\u00edstica conectada basada en tecnolog\u00eda Beacons y gestionada por la plataforma Inventrip. La primera implantaci\u00f3n ha sido en la Ruta del Vino Ribera del Duero, creando con ello un canal de informaci\u00f3n offline (se\u00f1alizaci\u00f3n tur\u00edstica) y online (conexi\u00f3n al smartphone del visitante) donde cada se\u00f1al funciona como una oficina de turismo digital. A trav\u00e9s de Inventrip se conecta el territorio con el turista digital, reduciendo la dependencia de la Ruta de intermediarios online y dando visibilidad a sus 80 pueblos y 151 establecimientos asociados que aportan m\u00e1s de 190 opciones de ocio.\n\n\n\n\nCatalunya\n\n\n\n\n(14/12/2017) \nBarcelona aplica un sistema de predicci\u00f3n de plazas de aparcamiento a trav\u00e9s de una App\n: La empresa p\u00fablica Barcelona Serveis Municipals (B:SM) ha presentado el Sistema de Informaci\u00f3n al Usuario (SIU), un sistema de predicci\u00f3n de ocupaci\u00f3n de plazas de aparcamiento para facilitar la b\u00fasqueda de estacionamiento regulado de AREA (zona azul o verde preferente) a los conductores a trav\u00e9s de una App.",
            "title": "Smart Cities"
        },
        {
            "location": "/smart_cities/#smart-cities",
            "text": "",
            "title": "Smart Cities"
        },
        {
            "location": "/smart_cities/#enlaces-documentacion-recursos",
            "text": "",
            "title": "Enlaces, documentaci\u00f3n, recursos"
        },
        {
            "location": "/smart_cities/#noticias",
            "text": "",
            "title": "Noticias"
        },
        {
            "location": "/smart_cities/#centro",
            "text": "",
            "title": "Centro"
        },
        {
            "location": "/smart_cities/#sur",
            "text": "(20/12/2017)  M\u00e1laga sustituir\u00e1 m\u00e1s de 6.000 puntos de luz por tecnolog\u00eda LED : El Ayuntamiento de M\u00e1laga, a trav\u00e9s del \u00e1rea de Servicios Operativos, renovar\u00e1 gracias a su Plan \u2018M\u00e1s barrios, m\u00e1s M\u00e1laga\u2019 de Inversiones Financieramente Sostenibles m\u00e1s de 6.000 puntos de luz en 1.223 calles de la ciudad para abaratar el consumo el\u00e9ctrico y mejorar la calidad del alumbrado. De esta manera se va ampliando paulatinamente a toda la ciudad la instalaci\u00f3n de tecnolog\u00eda led. En estos momentos la capital cuenta con un 10% de farolas con tecnolog\u00eda led y con la ejecuci\u00f3n de este nuevo contrato se pasar\u00e1 a un 20% de los 64.000 puntos de luz que hay en M\u00e1laga. En concreto, en 2018 se beneficiar\u00e1n de esta renovaci\u00f3n los distritos de Bail\u00e9n Miraflores, Ciudad Jard\u00edn y Palma-Palmilla.  (19/12/2017)  Andaluc\u00eda crea una plataforma Smart Data para conocer mejor al visitante y optimizar sus destinos tur\u00edsticos : Andaluc\u00eda cuenta con una herramienta para el turismo en la comunidad con el primer Smart Data regional y p\u00fablico, que permitir\u00e1 a destinos y empresas perfeccionar la experiencia del cliente, conocer mejor el mercado al que se dirigen, optimizar las acciones promocionales y de planificaci\u00f3n en funci\u00f3n del inter\u00e9s y el grado de satisfacci\u00f3n del viajero y programar las campa\u00f1as tur\u00edsticas.  (18/12/2017)  El Parlamento de Andaluc\u00eda aprueba la Ley de Participaci\u00f3n Ciudadana de la Comunidad Aut\u00f3noma : El Pleno del Parlamento de Andaluc\u00eda ha aprobado la Ley de Participaci\u00f3n Ciudadana de Andaluc\u00eda, que impulsar\u00e1 en la comunidad aut\u00f3noma nuevas formas de democracia directa complementarias del modelo representativo. El texto regula la ampliaci\u00f3n del derecho de participaci\u00f3n y de las f\u00f3rmulas de gobierno abierto y transparencia ya recogidas en el Estatuto de Autonom\u00eda, posibilitando su ejercicio dentro de los l\u00edmites del actual marco legislativo y haci\u00e9ndolo extensible a los mayores de 16 a\u00f1os con vecindad en Andaluc\u00eda.",
            "title": "Sur"
        },
        {
            "location": "/smart_cities/#este",
            "text": "(14/12/2017)  Valencia instalar\u00e1 3.000 luminarias con telegesti\u00f3n punto a punto : Los distritos de la zona Norte de Valencia contar\u00e1n con nuevas luminarias equipadas con dispositivos de telegesti\u00f3n punto a punto con comunicaci\u00f3n bidireccional, lo que permite a los gestores en los centros de mandos conocer, de manera remota, tanto la evoluci\u00f3n del consumo en cada momento, como las posibles aver\u00edas del sistema en tiempo real.  (14/12/2017)  Murcia participa junto a ciudades de Jap\u00f3n en el desarrollo de una plataforma abierta de Ciudad Inteligente : Murcia es la \u00fanica ciudad espa\u00f1ola que desarrolla junto con Tokio, Sapporo, Yokosuku, \u00c1msterdam y Zurich una plataforma abierta que sirva de base para una infraestructura de datos de ciudad inteligente.",
            "title": "Este"
        },
        {
            "location": "/smart_cities/#norte",
            "text": "(19/12/2017) Ruta Smart Ribera del Duero: se\u00f1alizaci\u00f3n tur\u00edstica inteligente conectada con Inventrip :  Sismotur  ha creado una red global de se\u00f1alizaci\u00f3n tur\u00edstica conectada basada en tecnolog\u00eda Beacons y gestionada por la plataforma Inventrip. La primera implantaci\u00f3n ha sido en la Ruta del Vino Ribera del Duero, creando con ello un canal de informaci\u00f3n offline (se\u00f1alizaci\u00f3n tur\u00edstica) y online (conexi\u00f3n al smartphone del visitante) donde cada se\u00f1al funciona como una oficina de turismo digital. A trav\u00e9s de Inventrip se conecta el territorio con el turista digital, reduciendo la dependencia de la Ruta de intermediarios online y dando visibilidad a sus 80 pueblos y 151 establecimientos asociados que aportan m\u00e1s de 190 opciones de ocio.",
            "title": "Norte"
        },
        {
            "location": "/smart_cities/#catalunya",
            "text": "(14/12/2017)  Barcelona aplica un sistema de predicci\u00f3n de plazas de aparcamiento a trav\u00e9s de una App : La empresa p\u00fablica Barcelona Serveis Municipals (B:SM) ha presentado el Sistema de Informaci\u00f3n al Usuario (SIU), un sistema de predicci\u00f3n de ocupaci\u00f3n de plazas de aparcamiento para facilitar la b\u00fasqueda de estacionamiento regulado de AREA (zona azul o verde preferente) a los conductores a trav\u00e9s de una App.",
            "title": "Catalunya"
        },
        {
            "location": "/fiware/",
            "text": "FIWARE\n\n\n\n\nEnlaces, documentaci\u00f3n, recursos\n\n\n\n\nFIWARE IoT Stack\n: punto de entrada a toda la documentaci\u00f3n de FIWARE sobre el stack sw de IoT.\n\n\nQuick start on device connection to the platform (with Ultralight 2.0)\n: guia r\u00e1pida sobre c\u00f3mo conectar dispositivos IoT a la plataforma usando el protocolo Ultralight 2.0: registro del dispositivo, env\u00edo de medidas y env\u00edo de comandos al dispositivo.\n\n\nC\u00f3mo conectar una \u201ccosa\u201d por HTTP utilizando Ultralight 2.0\n: entrada del blog de \nSemotic\n, escrita por \nJos\u00e9 Benitez\n, en la que explican c\u00f3mo: Instalar, desplegar y configurar un stack IoT de FIWARE (IoT Agent UL y CB) usando docker y docker-compose; conectar un dispositivo Edison a la plataforma por UL2.0; conectar un sensor de temperatura y una pantalla LCD a la Edison; programar en Javascript (node.js) con el Intel SDK (en Mac); conectar un dashboard Freeboard a la plataforma.",
            "title": "FIWARE"
        },
        {
            "location": "/fiware/#fiware",
            "text": "",
            "title": "FIWARE"
        },
        {
            "location": "/fiware/#enlaces-documentacion-recursos",
            "text": "FIWARE IoT Stack : punto de entrada a toda la documentaci\u00f3n de FIWARE sobre el stack sw de IoT.  Quick start on device connection to the platform (with Ultralight 2.0) : guia r\u00e1pida sobre c\u00f3mo conectar dispositivos IoT a la plataforma usando el protocolo Ultralight 2.0: registro del dispositivo, env\u00edo de medidas y env\u00edo de comandos al dispositivo.  C\u00f3mo conectar una \u201ccosa\u201d por HTTP utilizando Ultralight 2.0 : entrada del blog de  Semotic , escrita por  Jos\u00e9 Benitez , en la que explican c\u00f3mo: Instalar, desplegar y configurar un stack IoT de FIWARE (IoT Agent UL y CB) usando docker y docker-compose; conectar un dispositivo Edison a la plataforma por UL2.0; conectar un sensor de temperatura y una pantalla LCD a la Edison; programar en Javascript (node.js) con el Intel SDK (en Mac); conectar un dashboard Freeboard a la plataforma.",
            "title": "Enlaces, documentaci\u00f3n, recursos"
        },
        {
            "location": "/video/",
            "text": "Video\n\n\n\n\nEnlaces, documentaci\u00f3n, recursos\n\n\nEn la web de documentaci\u00f3n \nMedium\n hay un articulo de Arpad Kuni, director de operaciones de red de Ustream, introductorio y divulgativo sobre algunos temas b\u00e1sicos de streaming. El art\u00edculo, titulado \nEnterprise Video Delivery - Where to start?\n, est\u00e1 enfocado al streaming interno, por red corporativa, pero comenta conceptos de codificaci\u00f3n y protocolos de \nlive streaming\n, como HLS o MPEG-DASH.\n\n\nNetflix\n\n\nEl test de velocidad que Netflix recomienda en su documentaci\u00f3n es \nFast\n.\n\n\nEl blog t\u00e9cnico de Netflix se llama \nThe Netflix Tech Blog\n.\n\n\nEn el art\u00edculo \nPer-Title Encode Optimization\n Netflix explica la nueva forma de codificar los archivos, dando informaci\u00f3n sobre c\u00f3mo lo hac\u00edan antes, con \nsettings\n fijos en funci\u00f3n de la resoluci\u00f3n, sin tener en cuenta la complejidad variable de las im\u00e1genes codificadas. Ahora codifican con calidad variable en funci\u00f3n de la complejidad. En el art\u00edculo hay informaci\u00f3n general sobre codificaci\u00f3n, y una tabla de Mbit/s en funci\u00f3n de la resoluci\u00f3n.\n\n\nWowza\n\n\nLa web del proveedor de tecnolog\u00eda para streaming \nWowza\n tiene varios recursos de aprendizaje (documentaci\u00f3n, videos, etc.) entre ellos un blog con varios art\u00edculos interesantes sobre streaming y \nlow latency live streaming\n:\n\n\n\n\nLow-Latency Streaming: What Is It & Do You Need It?\n\n\nHLS Latency Sucks, But Here\u2019s How to Fix It\n\n\nStreaming 101 Posts\n\n\nWowza Whiteboard: Low-Latency Streaming Basics\n: cuatro art\u00edculos en video explicando conceptos generales de \nlow latency live streaming\n\n\n\n\nStreaming Learning Center\n\n\nLa web \nStreaming Learning Center\n es una web de un experto en streaming que se dedica profesionalmente a formaci\u00f3n y consultor\u00eda. Tiene una secci\u00f3n de \nlibros\n y una secci\u00f3n de \nblog\n. En el blog hay art\u00edculos interesantes, muchos de ellos contienen los \nhandouts\n de sus sesiones de formaci\u00f3n, y se pueden descargar en PDF.\n\n\nEl libro \nVideo Encoding by the Numbers\n es una \nbiblia\n del tema.\n\n\n\n\nAncho de banda\n\n\n\n\nCalidad SD: recomendado 3Mbits/s\n\n\nCalidad HD: recomendado 5Mbits/s\n\n\nCalidad UltraHD: recomentado 25Mbits/s\n\n\n\n\nCalidades\n\n\nHD\n\n\nResoluci\u00f3n horizontal de 720p o 1080p.",
            "title": "Video"
        },
        {
            "location": "/video/#video",
            "text": "",
            "title": "Video"
        },
        {
            "location": "/video/#enlaces-documentacion-recursos",
            "text": "En la web de documentaci\u00f3n  Medium  hay un articulo de Arpad Kuni, director de operaciones de red de Ustream, introductorio y divulgativo sobre algunos temas b\u00e1sicos de streaming. El art\u00edculo, titulado  Enterprise Video Delivery - Where to start? , est\u00e1 enfocado al streaming interno, por red corporativa, pero comenta conceptos de codificaci\u00f3n y protocolos de  live streaming , como HLS o MPEG-DASH.",
            "title": "Enlaces, documentaci\u00f3n, recursos"
        },
        {
            "location": "/video/#netflix",
            "text": "El test de velocidad que Netflix recomienda en su documentaci\u00f3n es  Fast .  El blog t\u00e9cnico de Netflix se llama  The Netflix Tech Blog .  En el art\u00edculo  Per-Title Encode Optimization  Netflix explica la nueva forma de codificar los archivos, dando informaci\u00f3n sobre c\u00f3mo lo hac\u00edan antes, con  settings  fijos en funci\u00f3n de la resoluci\u00f3n, sin tener en cuenta la complejidad variable de las im\u00e1genes codificadas. Ahora codifican con calidad variable en funci\u00f3n de la complejidad. En el art\u00edculo hay informaci\u00f3n general sobre codificaci\u00f3n, y una tabla de Mbit/s en funci\u00f3n de la resoluci\u00f3n.",
            "title": "Netflix"
        },
        {
            "location": "/video/#wowza",
            "text": "La web del proveedor de tecnolog\u00eda para streaming  Wowza  tiene varios recursos de aprendizaje (documentaci\u00f3n, videos, etc.) entre ellos un blog con varios art\u00edculos interesantes sobre streaming y  low latency live streaming :   Low-Latency Streaming: What Is It & Do You Need It?  HLS Latency Sucks, But Here\u2019s How to Fix It  Streaming 101 Posts  Wowza Whiteboard: Low-Latency Streaming Basics : cuatro art\u00edculos en video explicando conceptos generales de  low latency live streaming",
            "title": "Wowza"
        },
        {
            "location": "/video/#streaming-learning-center",
            "text": "La web  Streaming Learning Center  es una web de un experto en streaming que se dedica profesionalmente a formaci\u00f3n y consultor\u00eda. Tiene una secci\u00f3n de  libros  y una secci\u00f3n de  blog . En el blog hay art\u00edculos interesantes, muchos de ellos contienen los  handouts  de sus sesiones de formaci\u00f3n, y se pueden descargar en PDF.  El libro  Video Encoding by the Numbers  es una  biblia  del tema.",
            "title": "Streaming Learning Center"
        },
        {
            "location": "/video/#ancho-de-banda",
            "text": "Calidad SD: recomendado 3Mbits/s  Calidad HD: recomendado 5Mbits/s  Calidad UltraHD: recomentado 25Mbits/s",
            "title": "Ancho de banda"
        },
        {
            "location": "/video/#calidades",
            "text": "",
            "title": "Calidades"
        },
        {
            "location": "/video/#hd",
            "text": "Resoluci\u00f3n horizontal de 720p o 1080p.",
            "title": "HD"
        },
        {
            "location": "/espacios_digitales/",
            "text": "Espacios Digitales\n\n\n\n\nOmnicanalidad y cliente omnicanal\n\n\nEjemplos de soluciones en las que las empresas de retail est\u00e1n invirtiendo (seg\u00fan Retail Technology Study 2016) son plataformas software y proyectos de integraci\u00f3n que permiten a los clientes finales:\n\n\n\n\nhacer compras online dentro de la tienda f\u00edsica\n\n\ncomprar o reservar art\u00edculos online y recogerlos en la tienda f\u00edsica\n\n\nutilizar stock de art\u00edculos de la tienda f\u00edsica para cursar un pedido online",
            "title": "Espacios Digitales"
        },
        {
            "location": "/espacios_digitales/#espacios-digitales",
            "text": "",
            "title": "Espacios Digitales"
        },
        {
            "location": "/espacios_digitales/#omnicanalidad-y-cliente-omnicanal",
            "text": "Ejemplos de soluciones en las que las empresas de retail est\u00e1n invirtiendo (seg\u00fan Retail Technology Study 2016) son plataformas software y proyectos de integraci\u00f3n que permiten a los clientes finales:   hacer compras online dentro de la tienda f\u00edsica  comprar o reservar art\u00edculos online y recogerlos en la tienda f\u00edsica  utilizar stock de art\u00edculos de la tienda f\u00edsica para cursar un pedido online",
            "title": "Omnicanalidad y cliente omnicanal"
        },
        {
            "location": "/data_science/general/",
            "text": "Data Science en general\n\n\nEnlaces, tutoriales, documentaci\u00f3n, libros\n\n\nData Science Primer: Basic Concepts for Beginners\n\n\nThis collection of concise introductory data science tutorials\n cover topics including the difference between data mining and statistics, supervised vs. unsupervised learning, and the types of patterns we can mine from data.\n\n\nMachine Learning is Fun!\n\n\nConjunto de 8 art\u00edculos en Medium. Nivel inicial, con buenas explicaciones e intuiciones para los diferentes conceptos.\n\n\nUpdate: This article is part of a series. Check out the full series: \nPart 1\n, \nPart 2\n, \nPart 3\n, \nPart 4\n, \nPart 5\n, \nPart 6\n, \nPart 7\n and \nPart 8!\n\n\nBigger update: The content of this article is now available as a \nfull-length video course that walks you through every step of the code\n. You can take the course for free (and access everything else on Lynda.com free for 30 days) if you \nsign up with this link\n.\n\n\nHave you heard people talking about machine learning but only have a fuzzy idea of what that means? Are you tired of nodding your way through conversations with co-workers? Let\u2019s change that!\n\n\nThis guide is for anyone who is curious about machine learning but has no idea where to start. I imagine there are a lot of people who tried reading the wikipedia article, got frustrated and gave up wishing someone would just give them a high-level explanation. That\u2019s what this is.\n\n\nCheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning & Big Data\n\n\nThe Most Complete List of Best AI Cheat Sheets. Over the past few months, I have been collecting AI cheat sheets. From time to time I share them with friends and colleagues and recently I have been getting asked a lot, so I decided to organize and share the entire collection. To make things more interesting and give context, I added descriptions and/or excerpts for each major topic.\n\n\nMachine Learning for Humans\n\n\nSimple, plain-English explanations accompanied by math, code, and real-world examples.\n\n\n[Update 9/2/17] This series is now available as a full-length e-book! \nDownload here\n.\n\n\nFor inquiries, please contact ml4humans@gmail.com.\n\n\nRoadmap\n\n\n\n\nPart 1: Why Machine Learning Matters\n. The big picture of artificial intelligence and machine learning\u200a\u2014\u200apast, present, and future.\n\n\nPart 2.1: Supervised Learning\n. Learning with an answer key. Introducing linear regression, loss functions, overfitting, and gradient descent.\n\n\nPart 2.2: Supervised Learning II\n. Two methods of classification: logistic regression and SVMs.\n\n\nPart 2.3: Supervised Learning III\n. Non-parametric learners: k-nearest neighbors, decision trees, random forests. Introducing cross-validation, hyperparameter tuning, and ensemble models.\n\n\nPart 3: Unsupervised Learning\n. Clustering: k-means, hierarchical. Dimensionality reduction: principal components analysis (PCA), singular value decomposition (SVD).\n\n\nPart 4: Neural Networks & Deep Learning\n. Why, where, and how deep learning works. Drawing inspiration from the brain. Convolutional neural networks (CNNs), recurrent neural networks (RNNs). Real-world applications.\n\n\nPart 5: Reinforcement Learning\n. Exploration and exploitation. Markov decision processes. Q-learning, policy learning, and deep reinforcement learning. The value learning problem.\n\n\nAppendix: The Best Machine Learning Resources\n. A curated list of resources for creating your machine learning curriculum.\n\n\n\n\nArticulos de la web Unsupervised Methods\n\n\nEn la web \nUnsupervised Methods\n hay varios art\u00edculos con recopilaciones de informaci\u00f3n muy interesantes, \"curated lists\" de art\u00edculos, cursos, bloggers, tutoriales, etc. Estos son los art\u00edculos que me han llamado la atenci\u00f3n:\n\n\n\n\nMy Curated List of AI and Machine Learning Resources from Around the Web\n: only include links to free content. There is enough free content to keep you busy for a while. It\u2019s amazing just how much information is available on machine learning, deep learning, and artificial intelligence on the web. This article should give you a sense of the scope. I\u2019ve created sections below that contain: well-known researchers, AI organizations, video courses, bloggers, Medium writers, books, YouTube channels, Quora topics, subreddits, Github repos, podcasts, newsletters, conferences, research links, tutorials, and cheat sheets.\n\n\nOver 150 of the Best Machine Learning, NLP, and Python Tutorials I\u2019ve Found\n: a list of the best tutorial content that I\u2019ve found so far. It\u2019s by no means an exhaustive list of every ML-related tutorial on the web\u200a\u2014\u200athat would be overwhelming and duplicative. Plus, there is a bunch of mediocre content out there. My goal was to link to the best tutorials I found on the important subtopics within machine learning and NLP. I\u2019ve split this post into four sections: Machine Learning, NLP, Python, and Math.\n\n\nCheat Sheet of Machine Learning and Python (and Math) Cheat Sheets\n: There are many facets to Machine Learning. As I started brushing up on the subject, I came across various \u201ccheat sheets\u201d that compactly listed all the key points I needed to know for a given topic. Eventually, I compiled over 20 Machine Learning-related cheat sheets. Some I reference frequently and thought others may benefit from them too. This post contains 27 of the better cheat sheets I\u2019ve found on the web. Let me know if I\u2019m missing any you like. Given how rapidly the Machine Learning space is evolving, I imagine these will go out of date quickly, but at least as of June 1, 2017, they are pretty current.\n\n\n\n\nEnlaces\n\n\n\n\nObject detection: an overview in the age of Deep Learning\n\n\nEssential Cheat Sheets for Machine Learning and Deep Learning Engineers\n: tiene tambi\u00e9n un \nrepositorio Github\n\n\nCheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning & Big Data\n: cheat sheets para topolog\u00edas de redes neuronales, numpy, scikit-learn, python basics for data science, pandas, bokeh, tensorflow, keras, data wrangling con pandas, data wrangling con dplyr y tidyr, algebra lineal con scipy, matplotlib, visualizaci\u00f3n de datos con ggplot2, complejidad de algoritmos, etc.\n\n\nProbabilistic programming from scratch\n: programaci\u00f3n probabil\u00edstica, inferencia Bayesiana\n\n\nJake Vanderplas - Statistics for Hackers - PyCon 2016\n\n\n\u00bfPedaleas en la ciudad?: Analiza con Excel la seguridad de los ciclistas en Madrid\n: art\u00edculo del blog de \nLUCA\n en el que se hace un an\u00e1lisis descriptivo de datos de accidentes de bicicleta descargados del portal de datos abiertos del ayuntamiento de Madrid. El an\u00e1lisis se hace con Excel, y hay informaci\u00f3n sobre caracter\u00edsticas y funciones avanzadas de las tablas din\u00e1micas\n\n\nTus datos m\u00e1s limpios...(II). Excel, \"Waterproof\"\n: otroart\u00edculo del blog de \nLUCA\n, en este se realiza un tratamiento y limpieza de datos usando Excel\n\n\nTus datos m\u00e1s limpios, casi sin frotar\n: art\u00edculo un poco flojillo del blog de \nLUCA\n sobre el problema de la limpieza de datos pero en el que se mencionan las herramientas de limpieza de datos \nOpenRefine\n, \nTrifacta Wrangler\n y \nDataCleaner\n. OpenRefine es una herramienta open source que se denominaba anteriormente Google Refine",
            "title": "General"
        },
        {
            "location": "/data_science/general/#data-science-en-general",
            "text": "",
            "title": "Data Science en general"
        },
        {
            "location": "/data_science/general/#enlaces-tutoriales-documentacion-libros",
            "text": "",
            "title": "Enlaces, tutoriales, documentaci\u00f3n, libros"
        },
        {
            "location": "/data_science/general/#data-science-primer-basic-concepts-for-beginners",
            "text": "This collection of concise introductory data science tutorials  cover topics including the difference between data mining and statistics, supervised vs. unsupervised learning, and the types of patterns we can mine from data.",
            "title": "Data Science Primer: Basic Concepts for Beginners"
        },
        {
            "location": "/data_science/general/#machine-learning-is-fun",
            "text": "Conjunto de 8 art\u00edculos en Medium. Nivel inicial, con buenas explicaciones e intuiciones para los diferentes conceptos.  Update: This article is part of a series. Check out the full series:  Part 1 ,  Part 2 ,  Part 3 ,  Part 4 ,  Part 5 ,  Part 6 ,  Part 7  and  Part 8!  Bigger update: The content of this article is now available as a  full-length video course that walks you through every step of the code . You can take the course for free (and access everything else on Lynda.com free for 30 days) if you  sign up with this link .  Have you heard people talking about machine learning but only have a fuzzy idea of what that means? Are you tired of nodding your way through conversations with co-workers? Let\u2019s change that!  This guide is for anyone who is curious about machine learning but has no idea where to start. I imagine there are a lot of people who tried reading the wikipedia article, got frustrated and gave up wishing someone would just give them a high-level explanation. That\u2019s what this is.",
            "title": "Machine Learning is Fun!"
        },
        {
            "location": "/data_science/general/#cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data",
            "text": "The Most Complete List of Best AI Cheat Sheets. Over the past few months, I have been collecting AI cheat sheets. From time to time I share them with friends and colleagues and recently I have been getting asked a lot, so I decided to organize and share the entire collection. To make things more interesting and give context, I added descriptions and/or excerpts for each major topic.",
            "title": "Cheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning &amp; Big Data"
        },
        {
            "location": "/data_science/general/#machine-learning-for-humans",
            "text": "Simple, plain-English explanations accompanied by math, code, and real-world examples.  [Update 9/2/17] This series is now available as a full-length e-book!  Download here .  For inquiries, please contact ml4humans@gmail.com.",
            "title": "Machine Learning for Humans"
        },
        {
            "location": "/data_science/general/#roadmap",
            "text": "Part 1: Why Machine Learning Matters . The big picture of artificial intelligence and machine learning\u200a\u2014\u200apast, present, and future.  Part 2.1: Supervised Learning . Learning with an answer key. Introducing linear regression, loss functions, overfitting, and gradient descent.  Part 2.2: Supervised Learning II . Two methods of classification: logistic regression and SVMs.  Part 2.3: Supervised Learning III . Non-parametric learners: k-nearest neighbors, decision trees, random forests. Introducing cross-validation, hyperparameter tuning, and ensemble models.  Part 3: Unsupervised Learning . Clustering: k-means, hierarchical. Dimensionality reduction: principal components analysis (PCA), singular value decomposition (SVD).  Part 4: Neural Networks & Deep Learning . Why, where, and how deep learning works. Drawing inspiration from the brain. Convolutional neural networks (CNNs), recurrent neural networks (RNNs). Real-world applications.  Part 5: Reinforcement Learning . Exploration and exploitation. Markov decision processes. Q-learning, policy learning, and deep reinforcement learning. The value learning problem.  Appendix: The Best Machine Learning Resources . A curated list of resources for creating your machine learning curriculum.",
            "title": "Roadmap"
        },
        {
            "location": "/data_science/general/#articulos-de-la-web-unsupervised-methods",
            "text": "En la web  Unsupervised Methods  hay varios art\u00edculos con recopilaciones de informaci\u00f3n muy interesantes, \"curated lists\" de art\u00edculos, cursos, bloggers, tutoriales, etc. Estos son los art\u00edculos que me han llamado la atenci\u00f3n:   My Curated List of AI and Machine Learning Resources from Around the Web : only include links to free content. There is enough free content to keep you busy for a while. It\u2019s amazing just how much information is available on machine learning, deep learning, and artificial intelligence on the web. This article should give you a sense of the scope. I\u2019ve created sections below that contain: well-known researchers, AI organizations, video courses, bloggers, Medium writers, books, YouTube channels, Quora topics, subreddits, Github repos, podcasts, newsletters, conferences, research links, tutorials, and cheat sheets.  Over 150 of the Best Machine Learning, NLP, and Python Tutorials I\u2019ve Found : a list of the best tutorial content that I\u2019ve found so far. It\u2019s by no means an exhaustive list of every ML-related tutorial on the web\u200a\u2014\u200athat would be overwhelming and duplicative. Plus, there is a bunch of mediocre content out there. My goal was to link to the best tutorials I found on the important subtopics within machine learning and NLP. I\u2019ve split this post into four sections: Machine Learning, NLP, Python, and Math.  Cheat Sheet of Machine Learning and Python (and Math) Cheat Sheets : There are many facets to Machine Learning. As I started brushing up on the subject, I came across various \u201ccheat sheets\u201d that compactly listed all the key points I needed to know for a given topic. Eventually, I compiled over 20 Machine Learning-related cheat sheets. Some I reference frequently and thought others may benefit from them too. This post contains 27 of the better cheat sheets I\u2019ve found on the web. Let me know if I\u2019m missing any you like. Given how rapidly the Machine Learning space is evolving, I imagine these will go out of date quickly, but at least as of June 1, 2017, they are pretty current.",
            "title": "Articulos de la web Unsupervised Methods"
        },
        {
            "location": "/data_science/general/#enlaces",
            "text": "Object detection: an overview in the age of Deep Learning  Essential Cheat Sheets for Machine Learning and Deep Learning Engineers : tiene tambi\u00e9n un  repositorio Github  Cheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning & Big Data : cheat sheets para topolog\u00edas de redes neuronales, numpy, scikit-learn, python basics for data science, pandas, bokeh, tensorflow, keras, data wrangling con pandas, data wrangling con dplyr y tidyr, algebra lineal con scipy, matplotlib, visualizaci\u00f3n de datos con ggplot2, complejidad de algoritmos, etc.  Probabilistic programming from scratch : programaci\u00f3n probabil\u00edstica, inferencia Bayesiana  Jake Vanderplas - Statistics for Hackers - PyCon 2016  \u00bfPedaleas en la ciudad?: Analiza con Excel la seguridad de los ciclistas en Madrid : art\u00edculo del blog de  LUCA  en el que se hace un an\u00e1lisis descriptivo de datos de accidentes de bicicleta descargados del portal de datos abiertos del ayuntamiento de Madrid. El an\u00e1lisis se hace con Excel, y hay informaci\u00f3n sobre caracter\u00edsticas y funciones avanzadas de las tablas din\u00e1micas  Tus datos m\u00e1s limpios...(II). Excel, \"Waterproof\" : otroart\u00edculo del blog de  LUCA , en este se realiza un tratamiento y limpieza de datos usando Excel  Tus datos m\u00e1s limpios, casi sin frotar : art\u00edculo un poco flojillo del blog de  LUCA  sobre el problema de la limpieza de datos pero en el que se mencionan las herramientas de limpieza de datos  OpenRefine ,  Trifacta Wrangler  y  DataCleaner . OpenRefine es una herramienta open source que se denominaba anteriormente Google Refine",
            "title": "Enlaces"
        },
        {
            "location": "/data_science/cursos/",
            "text": "Cursos de Data Science\n\n\nFoundations of Data Science\n\n\nFoundations of Data Science: A Data Science Course for Everyone\n es un curso de la Universidad de Berkeley de nivel introductorio, apto para estudiantes de entrada de cualquier universidad, que ha sido espec\u00edficamente dise\u00f1ado para estudiantes que no han recibido previamente ning\u00fan curso sobre estad\u00edstica o data science. Todos los materiales est\u00e1n disponibles en la \nweb del curso\n, as\u00ed como el \nlibro de texto del curso\n, los \nvideos de las clases\n y las \nslides del curso\n.\n\n\nEl curso hace un uso extensivo de la herramienta \nJupyter Notebook\n que se explica en el art\u00edculo \nThe course of the future \u2013 and the technology behind it\n.\n\n\nPlan de estudios \"Machine Learning for Software Engineers\"\n\n\nUn ingeniero de software vietnamita, Nam Vu, ha dise\u00f1ado un plan de estudios para convertirse en data scientist. El plan est\u00e1 dise\u00f1ado considerando que un ingeniero de software no ha recibido tanta formaci\u00f3n matem\u00e1tica como la que recibe un estudiante universitario americano de \nComputer Science\n y est\u00e1 muy orientado a conseguir resultados pr\u00e1cticos con los modelos, a conseguir lo que se pretente (predecir, clasificar, etc) y menos orientado a dar las bases te\u00f3ricas que sustentan las diferentes t\u00e9cnicas y modelos (todo esto seg\u00fan la descripci\u00f3n del plan de estudios que hace el propio autor).\n\n\nEn el portal Medium hay dos art\u00edculos en los que el autor explica el plan de estudios, las motivaciones para crearlo, los objetivos que persegu\u00eda y consejos para cualquiera que quiera seguirlo. Los art\u00edculos son \nHow I plan to become a machine learning engineer\n y \nTop-down learning path: Machine Learning for Software Engineers\n. El plan de estudios en s\u00ed est\u00e1 en el repositorio github \nTop-down learning path: Machine Learning for Software Engineers\n, que tiene 16k+ \nstars\n.\n\n\nCurso de Machine Learning de Andrew Ng\n\n\nAndrew Ng is the former chief scientist at Baidu and is the adjunct professor at Stanford University. But perhaps he\u2019s more famously known for being the co-founder and chairman of Coursera.\n\n\nAt Coursera, Ng started one of the most famous Machine Learning MOOCs (Massively Open Online Course) known to date! While it can be quite \u201cdumbed down\u201d, it is still highly regarded as one of the best places to jump into machine learning. His course can be found \nhere\n.\n\n\nCurso de Machine Learning de la Carnegie Mellon University (prof. Tom Mitchell)\n\n\nThis course covers the theory and practical algorithms for machine learning\n from a variety of perspectives. We cover topics such as Bayesian networks, decision tree learning, Support Vector Machines, statistical learning methods, unsupervised learning and reinforcement learning. The course covers theoretical concepts such as inductive bias, the PAC learning framework, Bayesian learning methods, margin-based learning, and Occam's Razor. Short programming assignments include hands-on experiments with various learning algorithms. This course is designed to give a graduate-level student a thorough grounding in the methodologies, technologies, mathematics and algorithms currently needed by people who do research in machine learning.\n\n\nThe video lectures of the course are \nhere\n.\n\n\nCurso de Machine Learning de Udacity\n\n\nSimilar to Andrew Ng, Sebastian Thrun is a Stanford Professor and is also co-founder and chairman of a MOOC, Udacity. He is also the CEO of the Kitty Hawk Corporation, and founded Google X and Google\u2019s self driving car team.\n\n\nRivaled to Coursera, Udacity is also one of the leading MOOCs and has their own machine learning course. Udacity\u2019s machine learning course is a tad more difficult than Coursera\u2019s. Therefore it would be wiser to start with Andrew Ng\u2019s and then move on to this one. The course can be found \nhere\n.\n\n\nCS231n: Convolutional Neural Networks for Visual Recognition\n\n\nComputer Vision has become ubiquitous in our society, with applications in search, image understanding, apps, mapping, medicine, drones, and self-driving cars. Core to many of these applications are visual recognition tasks such as image classification, localization and detection. Recent developments in neural network (aka \u201cdeep learning\u201d) approaches have greatly advanced the performance of these state-of-the-art visual recognition systems. \nThis course\n is a deep dive into details of the deep learning architectures with a focus on learning end-to-end models for these tasks, particularly image classification. During the 10-week course, students will learn to implement, train and debug their own neural networks and gain a detailed understanding of cutting-edge research in computer vision. The final assignment will involve training a multi-million parameter convolutional neural network and applying it on the largest image classification dataset (ImageNet). We will focus on teaching how to set up the problem of image recognition, the learning algorithms (e.g. backpropagation), practical engineering tricks for training and fine-tuning the networks and guide the students through hands-on assignments and a final course project. Much of the background and materials of this course will be drawn from the \nImageNet Challenge\n.\n\n\nThese notes\n accompany the course: tutorials about Python, iPython, Google Cloud, Google GPUs, neural networks, convolutional neural networks. Worth reading.\n\n\n42 Steps to Mastering Data Science\n\n\nThis post\n is a collection of 6 separate posts of 7 steps a piece, each for mastering and better understanding a particular data science topic, with topics ranging from data preparation, to machine learning, to SQL databases, to NoSQL and beyond.\n\n\n7 Steps to Mastering Data Preparation with Python\n\n\nData preparation, cleaning, pre-processing, cleansing, wrangling. Whatever term you choose, they refer to a roughly related set of pre-modeling data activities in the machine learning, data mining, and data science communities.\n\n\n7 Steps to Mastering Machine Learning With Python\n\n\nThis post aims to take a newcomer from minimal knowledge of machine learning in Python all the way to knowledgeable practitioner in 7 steps, all while using freely available materials and resources along the way. The prime objective of this outline is to help you wade through the numerous free options that are available; there are many, to be sure, but which are the best? Which complement one another? What is the best order in which to use selected resources?\n\n\n7 More Steps to Mastering Machine Learning With Python\n\n\nAfter a quick review -- and a few options for a fresh perspective -- this post will focus more categorically on several sets of related machine learning tasks. Since we can safely skip the foundational modules this time around -- Python basics, machine learning basics, etc. -- we will jump right into the various machine learning algorithms. We can also categorize our tutorials better along functional lines this time.\n\n\n7 Steps to Understanding Deep Learning\n\n\nThis collection of reading materials and tutorials aims to provide a path for a deep neural networks newcomer to gain some understanding of this vast and complex topic. Though I do not assume any real understanding of neural networks or deep learning, I will assume your familiarity with general machine learning theory and practice to some degree. To overcome any deficiency you may have in the general areas of machine learning theory or practice you can consult the recent KDnuggets post 7 Steps to Mastering Machine Learning With Python. Since we will also see examples implemented in Python, some familiarity with the language will be useful. Introductory and review resources are also available in the previously mentioned post.\n\n\n7 Steps to Mastering SQL for Data Science\n\n\nClearly, SQL is important in data science. As such, this post aims to take a reader from SQL newbie to competent practitioner in a short time, using freely-available online resources. Lots of such resources exist on the internet, but mapping out a path from start to finish, using items which complement each other, is not always as straightforward as it may seem. Hopefully this post can be of assistance in this manner.\n\n\n7 Steps to Understanding NoSQL Databases\n\n\nThe term NoSQL has come to be synonymous with schema-less, non-relational data storage schemes. NoSQL is an umbrella term, one which encompasses a number of different technologies. These different technologies aren't even necessarily related in any way beyond the single defining characteristic of NoSQL: they are not relational in nature; for right or wrong, Structured Query Language (SQL) has become conflated with relational database management systems over the years.\n\n\nKok-Leong Seow, Kseow.com (@KokLeongSeow)\n\n\nKok-Leong Seow, a CS graduate student at Columbia University under Hod Lipson, is the youngest on this list. Kok-Leong has worked on creating \nquantum neural networks\n and is the creator of \nKSEOW.com\n, a leading website that teaches machine learning intuitively.\n\n\nKok-Leong takes an extremely different approach in teaching machine learning. Kok-Leong relies heavily on \u201cweird\u201d analogies and uses old methods like the Method of Loci to give intuition and drive concepts home. Kok-Leong is one of the only people that has content that \u201ctells a story\u201d to teach machine learning. The website can be found \nhere\n.\n\n\nAndrej Karpathy, karpathy.github.io (@karpathy)\n\n\nAndrej Karpathy was previously a Research Scientist at OpenAI, and CS graduate student at Stanford University. He is now the director of AI at Tesla, appointed by Elon Musk.\n\n\nAndrej\u2019s blog, karpathy.github.io, provides good insights on niche subjects in machine learning. It is by no means supposed to serve as an introduction or tutorial on machine learning. However, for more experienced practitioners, his blog can serve to be extremely useful. He even provides other gems like \u201cA Survival Guide to a PhD\u201d. His blog can be found \nhere\n.",
            "title": "Cursos"
        },
        {
            "location": "/data_science/cursos/#cursos-de-data-science",
            "text": "",
            "title": "Cursos de Data Science"
        },
        {
            "location": "/data_science/cursos/#foundations-of-data-science",
            "text": "Foundations of Data Science: A Data Science Course for Everyone  es un curso de la Universidad de Berkeley de nivel introductorio, apto para estudiantes de entrada de cualquier universidad, que ha sido espec\u00edficamente dise\u00f1ado para estudiantes que no han recibido previamente ning\u00fan curso sobre estad\u00edstica o data science. Todos los materiales est\u00e1n disponibles en la  web del curso , as\u00ed como el  libro de texto del curso , los  videos de las clases  y las  slides del curso .  El curso hace un uso extensivo de la herramienta  Jupyter Notebook  que se explica en el art\u00edculo  The course of the future \u2013 and the technology behind it .",
            "title": "Foundations of Data Science"
        },
        {
            "location": "/data_science/cursos/#plan-de-estudios-machine-learning-for-software-engineers",
            "text": "Un ingeniero de software vietnamita, Nam Vu, ha dise\u00f1ado un plan de estudios para convertirse en data scientist. El plan est\u00e1 dise\u00f1ado considerando que un ingeniero de software no ha recibido tanta formaci\u00f3n matem\u00e1tica como la que recibe un estudiante universitario americano de  Computer Science  y est\u00e1 muy orientado a conseguir resultados pr\u00e1cticos con los modelos, a conseguir lo que se pretente (predecir, clasificar, etc) y menos orientado a dar las bases te\u00f3ricas que sustentan las diferentes t\u00e9cnicas y modelos (todo esto seg\u00fan la descripci\u00f3n del plan de estudios que hace el propio autor).  En el portal Medium hay dos art\u00edculos en los que el autor explica el plan de estudios, las motivaciones para crearlo, los objetivos que persegu\u00eda y consejos para cualquiera que quiera seguirlo. Los art\u00edculos son  How I plan to become a machine learning engineer  y  Top-down learning path: Machine Learning for Software Engineers . El plan de estudios en s\u00ed est\u00e1 en el repositorio github  Top-down learning path: Machine Learning for Software Engineers , que tiene 16k+  stars .",
            "title": "Plan de estudios \"Machine Learning for Software Engineers\""
        },
        {
            "location": "/data_science/cursos/#curso-de-machine-learning-de-andrew-ng",
            "text": "Andrew Ng is the former chief scientist at Baidu and is the adjunct professor at Stanford University. But perhaps he\u2019s more famously known for being the co-founder and chairman of Coursera.  At Coursera, Ng started one of the most famous Machine Learning MOOCs (Massively Open Online Course) known to date! While it can be quite \u201cdumbed down\u201d, it is still highly regarded as one of the best places to jump into machine learning. His course can be found  here .",
            "title": "Curso de Machine Learning de Andrew Ng"
        },
        {
            "location": "/data_science/cursos/#curso-de-machine-learning-de-la-carnegie-mellon-university-prof-tom-mitchell",
            "text": "This course covers the theory and practical algorithms for machine learning  from a variety of perspectives. We cover topics such as Bayesian networks, decision tree learning, Support Vector Machines, statistical learning methods, unsupervised learning and reinforcement learning. The course covers theoretical concepts such as inductive bias, the PAC learning framework, Bayesian learning methods, margin-based learning, and Occam's Razor. Short programming assignments include hands-on experiments with various learning algorithms. This course is designed to give a graduate-level student a thorough grounding in the methodologies, technologies, mathematics and algorithms currently needed by people who do research in machine learning.  The video lectures of the course are  here .",
            "title": "Curso de Machine Learning de la Carnegie Mellon University (prof. Tom Mitchell)"
        },
        {
            "location": "/data_science/cursos/#curso-de-machine-learning-de-udacity",
            "text": "Similar to Andrew Ng, Sebastian Thrun is a Stanford Professor and is also co-founder and chairman of a MOOC, Udacity. He is also the CEO of the Kitty Hawk Corporation, and founded Google X and Google\u2019s self driving car team.  Rivaled to Coursera, Udacity is also one of the leading MOOCs and has their own machine learning course. Udacity\u2019s machine learning course is a tad more difficult than Coursera\u2019s. Therefore it would be wiser to start with Andrew Ng\u2019s and then move on to this one. The course can be found  here .",
            "title": "Curso de Machine Learning de Udacity"
        },
        {
            "location": "/data_science/cursos/#cs231n-convolutional-neural-networks-for-visual-recognition",
            "text": "Computer Vision has become ubiquitous in our society, with applications in search, image understanding, apps, mapping, medicine, drones, and self-driving cars. Core to many of these applications are visual recognition tasks such as image classification, localization and detection. Recent developments in neural network (aka \u201cdeep learning\u201d) approaches have greatly advanced the performance of these state-of-the-art visual recognition systems.  This course  is a deep dive into details of the deep learning architectures with a focus on learning end-to-end models for these tasks, particularly image classification. During the 10-week course, students will learn to implement, train and debug their own neural networks and gain a detailed understanding of cutting-edge research in computer vision. The final assignment will involve training a multi-million parameter convolutional neural network and applying it on the largest image classification dataset (ImageNet). We will focus on teaching how to set up the problem of image recognition, the learning algorithms (e.g. backpropagation), practical engineering tricks for training and fine-tuning the networks and guide the students through hands-on assignments and a final course project. Much of the background and materials of this course will be drawn from the  ImageNet Challenge .  These notes  accompany the course: tutorials about Python, iPython, Google Cloud, Google GPUs, neural networks, convolutional neural networks. Worth reading.",
            "title": "CS231n: Convolutional Neural Networks for Visual Recognition"
        },
        {
            "location": "/data_science/cursos/#42-steps-to-mastering-data-science",
            "text": "This post  is a collection of 6 separate posts of 7 steps a piece, each for mastering and better understanding a particular data science topic, with topics ranging from data preparation, to machine learning, to SQL databases, to NoSQL and beyond.",
            "title": "42 Steps to Mastering Data Science"
        },
        {
            "location": "/data_science/cursos/#7-steps-to-mastering-data-preparation-with-python",
            "text": "Data preparation, cleaning, pre-processing, cleansing, wrangling. Whatever term you choose, they refer to a roughly related set of pre-modeling data activities in the machine learning, data mining, and data science communities.",
            "title": "7 Steps to Mastering Data Preparation with Python"
        },
        {
            "location": "/data_science/cursos/#7-steps-to-mastering-machine-learning-with-python",
            "text": "This post aims to take a newcomer from minimal knowledge of machine learning in Python all the way to knowledgeable practitioner in 7 steps, all while using freely available materials and resources along the way. The prime objective of this outline is to help you wade through the numerous free options that are available; there are many, to be sure, but which are the best? Which complement one another? What is the best order in which to use selected resources?",
            "title": "7 Steps to Mastering Machine Learning With Python"
        },
        {
            "location": "/data_science/cursos/#7-more-steps-to-mastering-machine-learning-with-python",
            "text": "After a quick review -- and a few options for a fresh perspective -- this post will focus more categorically on several sets of related machine learning tasks. Since we can safely skip the foundational modules this time around -- Python basics, machine learning basics, etc. -- we will jump right into the various machine learning algorithms. We can also categorize our tutorials better along functional lines this time.",
            "title": "7 More Steps to Mastering Machine Learning With Python"
        },
        {
            "location": "/data_science/cursos/#7-steps-to-understanding-deep-learning",
            "text": "This collection of reading materials and tutorials aims to provide a path for a deep neural networks newcomer to gain some understanding of this vast and complex topic. Though I do not assume any real understanding of neural networks or deep learning, I will assume your familiarity with general machine learning theory and practice to some degree. To overcome any deficiency you may have in the general areas of machine learning theory or practice you can consult the recent KDnuggets post 7 Steps to Mastering Machine Learning With Python. Since we will also see examples implemented in Python, some familiarity with the language will be useful. Introductory and review resources are also available in the previously mentioned post.",
            "title": "7 Steps to Understanding Deep Learning"
        },
        {
            "location": "/data_science/cursos/#7-steps-to-mastering-sql-for-data-science",
            "text": "Clearly, SQL is important in data science. As such, this post aims to take a reader from SQL newbie to competent practitioner in a short time, using freely-available online resources. Lots of such resources exist on the internet, but mapping out a path from start to finish, using items which complement each other, is not always as straightforward as it may seem. Hopefully this post can be of assistance in this manner.",
            "title": "7 Steps to Mastering SQL for Data Science"
        },
        {
            "location": "/data_science/cursos/#7-steps-to-understanding-nosql-databases",
            "text": "The term NoSQL has come to be synonymous with schema-less, non-relational data storage schemes. NoSQL is an umbrella term, one which encompasses a number of different technologies. These different technologies aren't even necessarily related in any way beyond the single defining characteristic of NoSQL: they are not relational in nature; for right or wrong, Structured Query Language (SQL) has become conflated with relational database management systems over the years.",
            "title": "7 Steps to Understanding NoSQL Databases"
        },
        {
            "location": "/data_science/cursos/#kok-leong-seow-kseowcom-kokleongseow",
            "text": "Kok-Leong Seow, a CS graduate student at Columbia University under Hod Lipson, is the youngest on this list. Kok-Leong has worked on creating  quantum neural networks  and is the creator of  KSEOW.com , a leading website that teaches machine learning intuitively.  Kok-Leong takes an extremely different approach in teaching machine learning. Kok-Leong relies heavily on \u201cweird\u201d analogies and uses old methods like the Method of Loci to give intuition and drive concepts home. Kok-Leong is one of the only people that has content that \u201ctells a story\u201d to teach machine learning. The website can be found  here .",
            "title": "Kok-Leong Seow, Kseow.com (@KokLeongSeow)"
        },
        {
            "location": "/data_science/cursos/#andrej-karpathy-karpathygithubio-karpathy",
            "text": "Andrej Karpathy was previously a Research Scientist at OpenAI, and CS graduate student at Stanford University. He is now the director of AI at Tesla, appointed by Elon Musk.  Andrej\u2019s blog, karpathy.github.io, provides good insights on niche subjects in machine learning. It is by no means supposed to serve as an introduction or tutorial on machine learning. However, for more experienced practitioners, his blog can serve to be extremely useful. He even provides other gems like \u201cA Survival Guide to a PhD\u201d. His blog can be found  here .",
            "title": "Andrej Karpathy, karpathy.github.io (@karpathy)"
        },
        {
            "location": "/data_science/python/",
            "text": "Data Science en Python\n\n\nEnlaces, tutoriales, documentaci\u00f3n, libros\n\n\nEl autor Jake VanderPlas tiene una serie de art\u00edculos divulgativos en O'Reilly sobre Python y m\u00f3dulos de Python para data science:\n\n\n\n\nTodos los art\u00edculos est\u00e1n en \nPosts by Jake VanderPlas\n: Python, scikit-learn, handling missing data, Pandas, Seaborn, Support Vector Machines, etc\n\n\nA Whirlwind Tour of Python\n: tutorial de python, sintaxis, tipos de datos, m\u00f3dulos para data science, etc. Este art\u00edculo est\u00e1 disponible como ebook en formato \nepub\n, \nmobi\n y \npdf\n\n\nIntroduction to scikit-learn\n\n\nVarios art\u00edculos sobre Pandas: \nIntroducing Pandas Objects\n, \nOperations in Pandas\n, \nData Indexing and Selection\n, \nPivot Tables in Python\n\n\nIntroduction to Support Vector Machines\n\n\nData visualization with Seaborn\n\n\nHandling missing data\n\n\n\n\nEl libro de Jake VanderPlas se titula \nPython Data Science Handbook\n\n\nAn end to end implementation of a Machine Learning pipeline\n es un tutorial que cubre el ciclo completo de un proyecto de machine learning, empezando por la captura (\nscrapping\n) de datos, en este caso datos de pel\u00edculas obtenidos de IMDB y TMDB. El objetivo del proyecto es predecir el g\u00e9nero de una pel\u00edcula a partir de datos textuales y visuales (el poster de la pel\u00edcula). Se capturan los datos, se construye un dataset a partir de los datos capturados, se crean modelos prdictivos, tanto modelos \ntradicionales\n como modelos que utilizan \ndeep learning\n. Todo el c\u00f3digo en python est\u00e1 disponible en el \nrepositorio github del proyecto\n y en el \nREADME\n hay instrucciones de instalaci\u00f3n. Se utiliza Python 2.7 porque TensorFlow no es compatible con Python > 3.5.\n\n\nSe recomienda utilizar \nConda\n para instalar los paquetes cient\u00edficos de an\u00e1lisis de datos en Python (como NumPy o SciPy). Conda es un gestor de paquetes software (tipo apt o yum) hecho en Python y multiplataforma. Sirve para gestionar paquetes de software no s\u00f3lo de Python (de JavaScript, por ejemplo) aunque se utiliza fundamentalmente para Python. Por encima de Conda, se han creado distribuciones de Python que incluyen tambi\u00e9n un conjunto de paquetes ya preinstalados y configurados, como por ejemplo Anaconda. En el art\u00edculo \nConda: Myths and Misconceptions\n hay una buena explicaci\u00f3n de Conda, las diferencias con pip+virtualenv, cu\u00e1ndo utilizar uno u otro y los motivos que llevaron a la creaci\u00f3n de Conda. Cuando se usa Conda, lo primero que se hace es crear un entorno y dentro de ese entorno se instala python y los paquetes necesarios.\n\n\nOtros enlaces\n\n\n\n\nQuick Tip: The easiest way to grab data out of a web page in Python\n: tutorial para hacer \nweb scrapping\n usando pandas, que tiene una funci\u00f3n que devuelve un data frame por cada tabla que tenga la p\u00e1gina web\n\n\n\n\nJupyter Notebook\n\n\nEnlaces\n\n\n\n\nWhat is Jupyter?\n: es una descripci\u00f3n introductoria muy buena sobre Jupyter, para qu\u00e9 sirve, c\u00f3mo instalarlo y usarlo, c\u00f3mo integrarlo con Docker para resolver los problemas de distribuci\u00f3n del software necesario para ejecurar los programas, etc. Explica el soporte que Github le da a Jupyter (si se sube un archivo .ipynb a un repositorio, Github ejecuta el c\u00f3digo y publica una p\u00e1gina est\u00e1tica con los resultados). Se menciona el entorno cloud \nBinder\n que permite ejecutar notebooks en la nube. Explica la forma de trabajar con Jupyter, Github y Docker para distribuir y compartir notebooks. Hay dockerfiles espec\u00edficos de Jupyter. Hay extensiones de Jupyter para crear elementos gr\u00e1ficos de aplicaci\u00f3n, para hacer dashboards, para crear mapas basados en OpenStreetMap, para hacer visualizaciones de datos en 2D y 3D, para d3.js. Explica para qu\u00e9 sirve la utilidad nbviewer y c\u00f3mo usarla. Tambi\u00e9n da una lista de notebooks en python sobre temas de data science y machine learning.\n\n\nThe Jupyter notebook\n: documentaci\u00f3n oficial\n\n\nJupyterHub\n: instalaci\u00f3n multiusuario de Jupyter. Se utiliza en el courso Foundations de la UC Berkeley\n\n\nZero to JupyterHub\n: documentaci\u00f3n sobre JupyterHub",
            "title": "Python"
        },
        {
            "location": "/data_science/python/#data-science-en-python",
            "text": "",
            "title": "Data Science en Python"
        },
        {
            "location": "/data_science/python/#enlaces-tutoriales-documentacion-libros",
            "text": "El autor Jake VanderPlas tiene una serie de art\u00edculos divulgativos en O'Reilly sobre Python y m\u00f3dulos de Python para data science:   Todos los art\u00edculos est\u00e1n en  Posts by Jake VanderPlas : Python, scikit-learn, handling missing data, Pandas, Seaborn, Support Vector Machines, etc  A Whirlwind Tour of Python : tutorial de python, sintaxis, tipos de datos, m\u00f3dulos para data science, etc. Este art\u00edculo est\u00e1 disponible como ebook en formato  epub ,  mobi  y  pdf  Introduction to scikit-learn  Varios art\u00edculos sobre Pandas:  Introducing Pandas Objects ,  Operations in Pandas ,  Data Indexing and Selection ,  Pivot Tables in Python  Introduction to Support Vector Machines  Data visualization with Seaborn  Handling missing data   El libro de Jake VanderPlas se titula  Python Data Science Handbook  An end to end implementation of a Machine Learning pipeline  es un tutorial que cubre el ciclo completo de un proyecto de machine learning, empezando por la captura ( scrapping ) de datos, en este caso datos de pel\u00edculas obtenidos de IMDB y TMDB. El objetivo del proyecto es predecir el g\u00e9nero de una pel\u00edcula a partir de datos textuales y visuales (el poster de la pel\u00edcula). Se capturan los datos, se construye un dataset a partir de los datos capturados, se crean modelos prdictivos, tanto modelos  tradicionales  como modelos que utilizan  deep learning . Todo el c\u00f3digo en python est\u00e1 disponible en el  repositorio github del proyecto  y en el  README  hay instrucciones de instalaci\u00f3n. Se utiliza Python 2.7 porque TensorFlow no es compatible con Python > 3.5.  Se recomienda utilizar  Conda  para instalar los paquetes cient\u00edficos de an\u00e1lisis de datos en Python (como NumPy o SciPy). Conda es un gestor de paquetes software (tipo apt o yum) hecho en Python y multiplataforma. Sirve para gestionar paquetes de software no s\u00f3lo de Python (de JavaScript, por ejemplo) aunque se utiliza fundamentalmente para Python. Por encima de Conda, se han creado distribuciones de Python que incluyen tambi\u00e9n un conjunto de paquetes ya preinstalados y configurados, como por ejemplo Anaconda. En el art\u00edculo  Conda: Myths and Misconceptions  hay una buena explicaci\u00f3n de Conda, las diferencias con pip+virtualenv, cu\u00e1ndo utilizar uno u otro y los motivos que llevaron a la creaci\u00f3n de Conda. Cuando se usa Conda, lo primero que se hace es crear un entorno y dentro de ese entorno se instala python y los paquetes necesarios.",
            "title": "Enlaces, tutoriales, documentaci\u00f3n, libros"
        },
        {
            "location": "/data_science/python/#otros-enlaces",
            "text": "Quick Tip: The easiest way to grab data out of a web page in Python : tutorial para hacer  web scrapping  usando pandas, que tiene una funci\u00f3n que devuelve un data frame por cada tabla que tenga la p\u00e1gina web",
            "title": "Otros enlaces"
        },
        {
            "location": "/data_science/python/#jupyter-notebook",
            "text": "",
            "title": "Jupyter Notebook"
        },
        {
            "location": "/data_science/python/#enlaces",
            "text": "What is Jupyter? : es una descripci\u00f3n introductoria muy buena sobre Jupyter, para qu\u00e9 sirve, c\u00f3mo instalarlo y usarlo, c\u00f3mo integrarlo con Docker para resolver los problemas de distribuci\u00f3n del software necesario para ejecurar los programas, etc. Explica el soporte que Github le da a Jupyter (si se sube un archivo .ipynb a un repositorio, Github ejecuta el c\u00f3digo y publica una p\u00e1gina est\u00e1tica con los resultados). Se menciona el entorno cloud  Binder  que permite ejecutar notebooks en la nube. Explica la forma de trabajar con Jupyter, Github y Docker para distribuir y compartir notebooks. Hay dockerfiles espec\u00edficos de Jupyter. Hay extensiones de Jupyter para crear elementos gr\u00e1ficos de aplicaci\u00f3n, para hacer dashboards, para crear mapas basados en OpenStreetMap, para hacer visualizaciones de datos en 2D y 3D, para d3.js. Explica para qu\u00e9 sirve la utilidad nbviewer y c\u00f3mo usarla. Tambi\u00e9n da una lista de notebooks en python sobre temas de data science y machine learning.  The Jupyter notebook : documentaci\u00f3n oficial  JupyterHub : instalaci\u00f3n multiusuario de Jupyter. Se utiliza en el courso Foundations de la UC Berkeley  Zero to JupyterHub : documentaci\u00f3n sobre JupyterHub",
            "title": "Enlaces"
        },
        {
            "location": "/data_science/R/",
            "text": "Data Science en R\n\n\nEnlaces, tutoriales, documentaci\u00f3n, libros\n\n\nEl art\u00edculo \nR\u2019s tidytext turns messy text into valuable insight\n comenta la \nutilizaci\u00f3n del m\u00f3dulo tydytext en la web StackOverflow\n para realizar miner\u00eda de texto en R. El art\u00edculo es un \nabstract\n del libro \nText Mining with R: A tidy approach\n. El libro est\u00e1 \ndisponible para su lectura online\n y tiene un \nrepositorio GitHub\n.",
            "title": "R"
        },
        {
            "location": "/data_science/R/#data-science-en-r",
            "text": "",
            "title": "Data Science en R"
        },
        {
            "location": "/data_science/R/#enlaces-tutoriales-documentacion-libros",
            "text": "El art\u00edculo  R\u2019s tidytext turns messy text into valuable insight  comenta la  utilizaci\u00f3n del m\u00f3dulo tydytext en la web StackOverflow  para realizar miner\u00eda de texto en R. El art\u00edculo es un  abstract  del libro  Text Mining with R: A tidy approach . El libro est\u00e1  disponible para su lectura online  y tiene un  repositorio GitHub .",
            "title": "Enlaces, tutoriales, documentaci\u00f3n, libros"
        },
        {
            "location": "/ssh/",
            "text": "Guia r\u00e1pida de ssh\n\n\n\n\nEnlaces, documentaci\u00f3n\n\n\n\n\nSSH via HTTP proxy in OSX\n\n\nConnect with SSH through a proxy\n\n\nConnecting to Your Linux Instance Using SSH\n\n\n\n\n\n\nUsar ssh detr\u00e1s de un proxy\n\n\nEl comando para realizar una conexi\u00f3n ssh a trav\u00e9s de un servidor proxy es:\n\n\n$ ssh <user>@<host> -o \"ProxyCommand=nc -X connect -x <proxyhost>:<proxyport> %h %p\"\n\n\n\n\nPor ejemplo:\n\n\n$ ssh asainz@sulaco.ttcloud.net -o \"ProxyCommand=nc -X connect -x proxyinternet.tesa:8080 %h %p\"\n\n\n\n\nPara que este comando funcione, el servidor proxy tiene que aceptar el m\u00e9todo de conexi\u00f3n \nCONNECT\n y el comando \nnc\n tiene que estar instalado en el sistema.\n\n\nPara usar un proxy socks5 el comando es:\n\n\n$ ssh <user>@<host> -o \"ProxyCommand=nc -X 5 -x <proxyhost>:<proxyport> %h %p\"\n\n\n\n\nY para usar un proxy socks4 se utilizar\u00eda la opci\u00f3n \n-X 4\n.\n\n\nPara no tener que teclear el comando cada vez que se utiliza el cliente ssh se puede configurar esta opci\u00f3n en el archivo de configuraci\u00f3n de ssh, \n~/.ssh/config\n.\n\n\nSe puede a\u00f1adir la opci\u00f3n para todos los hosts:\n\n\nHost *\n    ProxyCommand          nc -X connect -x proxyhost:proxyport %h %p\n    ServerAliveInterval   10\n\n\n\nO para un host en concreto:\n\n\nHost sulaco.ttcloud.net\n    ProxyCommand          nc -X connect -x proxyhost:proxyport %h %p\n    ServerAliveInterval   10\n\n\n\nLa opci\u00f3n \nServerAliveInterval\nes para que el proxy no desconecte despu\u00e9s de un periodo de inactividad.\n\n\nnc en Mac OSX\n\n\nLa versi\u00f3n de nc de OSX tiene un problema de compatibilidad con los proxies http. No es compatible con proxies que utilizan HTTP 1.1, s\u00f3lo es compatible con HTTP 1.0. El proxy de Telef\u00f3nica utiliza HTTP 1.1, por lo que no se puede usar nc. Una alternativa que funciona perfectamente es \nncat\n, que forma parte del paquete \nnmap\n.\n\n\nLa opci\u00f3n para utilizar ncat en el archivo \n~/.ssh/config\n es:\n\n\nHost *\n    ProxyCommand          ncat --proxy proxyhost:proxyport --proxy-auth user:passwd %h %p\n\n\n\n\n\nAutenticaci\u00f3n con clave privada (archivos .pem)\n\n\nPara conectarse a m\u00e1quinas virtuales de Amazon y Fiware, hay que utilizar la autenticaci\u00f3n con clave privada (archivos .pem)\n\n\nConfiguraci\u00f3n del cliente\n\n\n\n\nSSH Config Files\n\n\n\n\nLa opci\u00f3n para conectarse a un servidor que requiere autenticaci\u00f3n por clave privada es \n-i <archivo.pem>\n:\n\n\n$ ssh <user>@<host> -i <path/file.pem>\n\n\n\n\nEl archivo .pem tiene que tener permisos de lectura \u00fanicamente para el propietario del archivo (\nchmod 400 <archivo.pem>\n).\n\n\nLa configurac\u00ed\u00f3n equivalente en el archivo \n~/.ssh/config\nser\u00eda:\n\n\nHost <host>\n    IdentityFile <path/file.pem>\n\n\n\nConfiguraci\u00f3n del servidor\n\n\nCuando el servidor ssh est\u00e1 configurado para aceptar \u00fanicamente conexiones sin password mediante clave privada, en el directorio \n.ssh\n del usuario hay que copiar el archivo \nauthorized_keys\n que se haya generado para el usuario por defecto de la maquina virtual.\n\n\nEl directorio \n.ssh\n tiene que tener permisos de lectura/escritura/ejecuci\u00f3n s\u00f3lo para el propietario (\nchmod 700 ~/.ssh\n) y el archivo \nauthorized_keys\n permisos de lectura/escritura \u00fanicamente para el propietario (\nchmod 600 ~/.ssh/authorized_keys\n).\n\n\nAdem\u00e1s, hay que comprobar que el el archivo de configuraci\u00f3n del servidor sshd (\n/etc/ssh/sshd_config\n) est\u00e9 autorizado el acceso por ssh para el nuevo usuario. Esto hay que hacerlo \nobligatoriamente en las m\u00e1quinas virtuales Ubuntu de Fiware\n.",
            "title": "Ssh"
        },
        {
            "location": "/ssh/#guia-rapida-de-ssh",
            "text": "",
            "title": "Guia r\u00e1pida de ssh"
        },
        {
            "location": "/ssh/#enlaces-documentacion",
            "text": "SSH via HTTP proxy in OSX  Connect with SSH through a proxy  Connecting to Your Linux Instance Using SSH",
            "title": "Enlaces, documentaci\u00f3n"
        },
        {
            "location": "/ssh/#usar-ssh-detras-de-un-proxy",
            "text": "El comando para realizar una conexi\u00f3n ssh a trav\u00e9s de un servidor proxy es:  $ ssh <user>@<host> -o \"ProxyCommand=nc -X connect -x <proxyhost>:<proxyport> %h %p\"  Por ejemplo:  $ ssh asainz@sulaco.ttcloud.net -o \"ProxyCommand=nc -X connect -x proxyinternet.tesa:8080 %h %p\"  Para que este comando funcione, el servidor proxy tiene que aceptar el m\u00e9todo de conexi\u00f3n  CONNECT  y el comando  nc  tiene que estar instalado en el sistema.  Para usar un proxy socks5 el comando es:  $ ssh <user>@<host> -o \"ProxyCommand=nc -X 5 -x <proxyhost>:<proxyport> %h %p\"  Y para usar un proxy socks4 se utilizar\u00eda la opci\u00f3n  -X 4 .  Para no tener que teclear el comando cada vez que se utiliza el cliente ssh se puede configurar esta opci\u00f3n en el archivo de configuraci\u00f3n de ssh,  ~/.ssh/config .  Se puede a\u00f1adir la opci\u00f3n para todos los hosts:  Host *\n    ProxyCommand          nc -X connect -x proxyhost:proxyport %h %p\n    ServerAliveInterval   10  O para un host en concreto:  Host sulaco.ttcloud.net\n    ProxyCommand          nc -X connect -x proxyhost:proxyport %h %p\n    ServerAliveInterval   10  La opci\u00f3n  ServerAliveInterval es para que el proxy no desconecte despu\u00e9s de un periodo de inactividad.",
            "title": "Usar ssh detr\u00e1s de un proxy"
        },
        {
            "location": "/ssh/#nc-en-mac-osx",
            "text": "La versi\u00f3n de nc de OSX tiene un problema de compatibilidad con los proxies http. No es compatible con proxies que utilizan HTTP 1.1, s\u00f3lo es compatible con HTTP 1.0. El proxy de Telef\u00f3nica utiliza HTTP 1.1, por lo que no se puede usar nc. Una alternativa que funciona perfectamente es  ncat , que forma parte del paquete  nmap .  La opci\u00f3n para utilizar ncat en el archivo  ~/.ssh/config  es:  Host *\n    ProxyCommand          ncat --proxy proxyhost:proxyport --proxy-auth user:passwd %h %p",
            "title": "nc en Mac OSX"
        },
        {
            "location": "/ssh/#autenticacion-con-clave-privada-archivos-pem",
            "text": "Para conectarse a m\u00e1quinas virtuales de Amazon y Fiware, hay que utilizar la autenticaci\u00f3n con clave privada (archivos .pem)",
            "title": "Autenticaci\u00f3n con clave privada (archivos .pem)"
        },
        {
            "location": "/ssh/#configuracion-del-cliente",
            "text": "SSH Config Files   La opci\u00f3n para conectarse a un servidor que requiere autenticaci\u00f3n por clave privada es  -i <archivo.pem> :  $ ssh <user>@<host> -i <path/file.pem>  El archivo .pem tiene que tener permisos de lectura \u00fanicamente para el propietario del archivo ( chmod 400 <archivo.pem> ).  La configurac\u00ed\u00f3n equivalente en el archivo  ~/.ssh/config ser\u00eda:  Host <host>\n    IdentityFile <path/file.pem>",
            "title": "Configuraci\u00f3n del cliente"
        },
        {
            "location": "/ssh/#configuracion-del-servidor",
            "text": "Cuando el servidor ssh est\u00e1 configurado para aceptar \u00fanicamente conexiones sin password mediante clave privada, en el directorio  .ssh  del usuario hay que copiar el archivo  authorized_keys  que se haya generado para el usuario por defecto de la maquina virtual.  El directorio  .ssh  tiene que tener permisos de lectura/escritura/ejecuci\u00f3n s\u00f3lo para el propietario ( chmod 700 ~/.ssh ) y el archivo  authorized_keys  permisos de lectura/escritura \u00fanicamente para el propietario ( chmod 600 ~/.ssh/authorized_keys ).  Adem\u00e1s, hay que comprobar que el el archivo de configuraci\u00f3n del servidor sshd ( /etc/ssh/sshd_config ) est\u00e9 autorizado el acceso por ssh para el nuevo usuario. Esto hay que hacerlo  obligatoriamente en las m\u00e1quinas virtuales Ubuntu de Fiware .",
            "title": "Configuraci\u00f3n del servidor"
        },
        {
            "location": "/vim/",
            "text": "Vim\n\n\n\n\nDocumentaci\u00f3n, tutoriales, enlaces, libros\n\n\nEn \nvimcasts.org\n hay 68 tutoriales en video y 50 art\u00edculos sobre Vim. Realizados por Drew Neil, el autor del libro \nPractical Vim\n.\n\n\nEl art\u00edculo \nMy experience with Vim\n tiene una lista de plugins recomendados.\n\n\nLibros\n\n\nA Byte of Vim\n es un libro sobre Vim (versi\u00f3n 7). Se puede leer online en la web del libro y tambi\u00e9n est\u00e1 disponible su descarga gratuita en formato ebook: \npdf\n, \nepub\n y \nmobi\n. El libro en formato \nraw\n est\u00e1 disponible en su \nrepositorio github\n.\n\n\nVim for humans\n es un libro introductorio cuyo objetivo es simplificar la curva de aprendizaje cuando se empieza a usar Vim.\n\n\n\n\n.vimrc\n\n\n\n\nColores / Esquemas de color\n\n\nEsquemas de color\n\n\n\n\nBase16\n\n\nSolarized\n\n\nGruvbox\n\n\nMolokai\n\n\nBadwolf\n\n\nWombat\n\n\nGithub\n\n\n\n\nBase16\n\n\nNo es s\u00f3lo un esquema de colores, es un \nframework\n que proporciona un esquema de 16 colores (tiene una combinaci\u00f3n de 16 colores por defecto pero hay muchas combinaciones diferentes) y una configuraci\u00f3n para hacer \nsyntax highlighting\n muy bien dise\u00f1ada.\n\n\n\n\nLa web principal del proyecto es \nhttps://github.com/chriskempson/base16\n\n\nLos diferentes temas creados con Base16 se pueden previsualizar en \nhttps://chriskempson.github.io/base16/\n\n\nLos temas Base16 para vim est\u00e1n en \nhttps://github.com/chriskempson/base16-vim\n\n\n\n\nInstalaci\u00f3n\n\n\nA\u00f1adir lo siguiente al \nvimrc\n y ejecutar \nPluginInstall\n en Vim:\n\n\nPlugin 'chriskempson/base16-vim'\n\n\n\n\nSeleccionar el esquema de color deseado, por ejemplo:\n\n\ncolorscheme base16-default-dark\n\n\n\n\nLa lista de temas de color disponibles en Base16 est\u00e1 en https://github.com/chriskempson/base16-vim/tree/master/colors.\n\n\nLa p\u00e1gina de Base16 para vim tiene bastantes recetas para configurar Base16 para vim en modo terminal. Consultar tambi\u00e9n https://github.com/chriskempson/base16-iterm2 para informaci\u00f3n sobre colores Base16 para iTerm2 y https://github.com/chriskempson/base16-shell, que es una utilidad para configurar los colores del terminal.\n\n\n[UPDATE: 02/08/17]\n: parece ser que hay emuladores de terminal en los que se puede cambiar la paleta de 256 colores, por ejemplo iTerm2. En el esquema de color Base16 se puede utilizar esta opci\u00f3n (cambiar la paleta de 256 colores) incluso se proporciona un \nshell script\n para cambiar los colores 17-21 de la paleta (para dejar los colores 0-15 sin cambiar y no afectar a otros programas) y versiones espec\u00edficas de los temas de color para esta configuraci\u00f3n. Hay m\u00e1s informaci\u00f3n sobre este tema en la p\u00e1gina \nHow to install base16 for iTerm2?\n.\n\n\nonedark.vim\n\n\nonedark.vim\n es un tema para vim inspirado en el excelente tema One Dark del editor Atom. El tema \nbase16-onedark\n del esquema de colores Base16 est\u00e1 inspirado en este tema. Este tema tiene versiones para \ntrue color\n y para las paletas de 16 y 256 colores.\n\n\nEn la secci\u00f3n de instalaci\u00f3n de la p\u00e1gina del tema hay instrucciones para:\n\n\n\n\ndetectar si el terminal tiene soporte para \ntrue color\n\n\nconfigurar tmux para usar el tema\n\n\nseleccionar las opciones de paleta de 16 y de 256 colores\n\n\nconfigurar vim-airline\n\n\nsolucionar problemas comununes con \ntrue color\n y las paletas de 16 y 256 colores\n\n\n\n\nTrue Color en el terminal\n\n\nEnlaces\n\n\n\n\nColours in terminal\n: un enlace a git con una explicaci\u00f3n muy buena sobre los diferentes modos de color de los emuladores de terminal, c\u00f3mo detectar si el emulador de terminal tiene soporte para \ntrue color\n y una lista de emuladores de terminal y programas con soporte para \ntrue color\n\n\nSupport for True Color (16 millions colors)\n: otro enlace a git con explicaci\u00f3n de modos de color en los emuladores de terminal y soporte para \ntrue color\n en diferentes programas. Tiene enlaces a utilidades interesantes, como un programa que es capaz de mostrar una imagen en el emulador de terminar cuando tiene soporte para \ntrue color\n\n\nUsing True Color in Vim with Tmux\n: una buena explicaci\u00f3n de los diferentes modos de color en los emuladores de terminal y un buen tutorial de c\u00f3mo activar el soporte para \ntrue color\n en vim y en \ntmux\n\n\n\n\nLos esquemas de color no se ven igual en versi\u00f3n \ngui\n que en terminal. Esto es porque en la versi\u00f3n \ngui\n vim utiliza todos los colores que proporciona el entorno gr\u00e1fico (utiliza \ntrue color\n) mientras que, por defecto, vim utiliza 256 colores en modo terminal, aunque el terminal tenga soporte para \ntrue color\n.\n\n\nEl emulador de terminal tiene tres modos de color:\n\n\n\n\npaleta de 16 colores\n\n\npaleta de 256 colores\n\n\npaleta de colores \ntrue color\n\n\n\n\nLa paleta de 16 colores est\u00e1 formada por 8 colores est\u00e1ndar y 8 variantes \"brillantes\" de esos colores est\u00e1ndar. Los colores est\u00e1ndar son: negro, rojo, verde, amarillo, azul, magenta, cyan y blanco. El negro \"est\u00e1ndar\" es negro mientras que el negro \"brillante\" es un gris oscuro. El blanco \"est\u00e1ndar\" es un gris claro mientras que el blanco \"brillante\" es blanco. Muchos programas de terminal asumen esta disposici\u00f3n de colores. La paleta de 16 colores s\u00ed que se puede cambiar por lo que, en teor\u00eda, se pueden configurar esos 16 colores para que sean iguales a los de la paleta del esquema de color. Lo que ocurre es que es muy probable que los colores que quedan bien en vim en cuanto se sale de vim y se ejecuta otro programa (por ejemplo tmux) ya se vean mal. El motivo es que el otro programa no tiene forma de saber que se ha cambiado la paleta de 16 colores y da por sentado que se est\u00e1 usando la paleta est\u00e1ndar de 16 colores. Por este motivo, no suele usarse esta opci\u00f3n (cambiar la paleta de 16 colores) para cambiar los colores de vim en modo terminal.\n\n\nLa paleta de 256 colores es fija, no se puede cambiar. Algunos esquemas de color tienen una versi\u00f3n de 256 colores, en la que utilizan los colores fijos m\u00e1s parecidos posible a los colores \ntrue color\n originales de la paleta. Esta es la opci\u00f3n m\u00e1s utilizada para cambiar los colores de vim en modo terminal, porque no se modifica la paleta de 16 colores y los otros programas de terminal no se ven afectados.\n\n\n[UPDATE: 02/08/17]\n: parece ser que hay emuladores de terminal en los que se puede cambiar la paleta de 256 colores, por ejemplo iTerm2. En el esquema de color Base16 se puede utilizar esta opci\u00f3n (cambiar la paleta de 256 colores) incluso se proporciona un \nshell script\n para cambiar los colores 17-21 de la paleta (para dejar los colores 0-15 sin cambiar y no afectar a otros programas) y versiones espec\u00edficas de los temas de color para esta configuraci\u00f3n.\n\n\nCuando el emulador de terminal tiene soporte para \ntrue color\n est\u00e1n disponibles 32 millones de colores (colores de 24 bits) por lo que cualquier paleta de colores de cualquier programa se ve perfectamente. Es exactamente igual que lo que pasa cuando se utiliza un escritorio gr\u00e1fico (Mac, Windows, etc). Esta es la opci\u00f3n recomendada.\n\n\nPara saber si un emulador de terminal tiene soporte para \ntrue color\n o no, el siguiente comando:\n\n\n$ printf \"\\x1b[38;2;255;100;0mTRUECOLOR\\x1b[0m\\n\"\n\n\n\n\ndebe escribir la palabra TRUECOLOR en color rojo en un emulador de terminal con soporte para \ntrue color\n. Tambi\u00e9n se puede ejecutar el siguiente comando \nawk\n, que en un terminar con soporte para \ntrue color\n debe mostrar un degradado de colores cont\u00ednuo:\n\n\n$ awk 'BEGIN{\n    s=\"/\\\\/\\\\/\\\\/\\\\/\\\\\"; s=s s s s s s s s;\n    for (colnum = 0; colnum<77; colnum++) {\n        r = 255-(colnum*255/76);\n        g = (colnum*510/76);\n        b = (colnum*255/76);\n        if (g>255) g = 510-g;\n        printf \"\\033[48;2;%d;%d;%dm\", r,g,b;\n        printf \"\\033[38;2;%d;%d;%dm\", 255-r,255-g,255-b;\n        printf \"%s\\033[0m\", substr(s,colnum+1,1);\n    }\n    printf \"\\n\";\n}'\n\n\n\n\nPara que vim utilice \ntrue colors\n en modo terminal hay que a\u00f1adir \nset termguicolors\n en \n.vimrc\n. Los terminales \nmintty\n (Cygwin), \niTerm2\n (Mac) y \ngnuterm\n (Linux) tienen soporte para \ntrue color\n.\n\n\n[UPDATE: 12/07/2017]\n Hay un problema con el \ncolorscheme\n \nSolarized\n en modo terminal con el \ntrue color\n activado. Los colores salen totalmente cambiados, tanto con el background light como dark.\n\n\n\n\nPlugin managers\n\n\nVundle\n\n\nVundle\n es un verdadero \nplugin manager\n, en el sentido de que, a partir de la configuraci\u00f3n que se hace en el archivo \n.vimrc\n, descarga autom\u00e1ticamente los plugins y tiene comandos para actualizar la versi\u00f3n de los plugins instalados, etc. Es m\u00e1s completo que \nPathogen\n en cuanto a funcionalidad.\n\n\nInstalaci\u00f3n\n\n\nUso\n\n\nPathogen\n\n\nInstalaci\u00f3n\n\n\nUso\n\n\n\n\nPlugins\n\n\nFugitive\n\n\nFugitive\n es un recubrimiento del comando git.\n\n\nTutoriales, documentaci\u00f3n\n\n\n\n\nHay una serie de 5 tutoriales en video en \nvimcasts.org\n. El primero de ellos es este: \nFugitive.vim - a complement to command line git\n\n\n\n\nInstalaci\u00f3n\n\n\nEn la secci\u00f3n de \nVundle\n de \n.vimrc\n, a\u00f1adir:\n\n\nPlugin 'tpope/vim-fugitive'\n\n\n\n\nUso\n\n\nLos comandos de Fugitive empiezan con G (g may\u00fascula). Se utilizan en modo vim normal, tecleando los dos puntos (:). Los comandos m\u00e1s habituales son:\n\n\n\n\nGwrite\n: guarda el archivo e invoca el commando \ngit add\n\n\nGread\n: descarta los cambios del archivo que se est\u00e1 editando y recupera la \u00faltima versi\u00f3n guardada en git. Una vez recuperada, vuelve a abrirla en el buffer de edici\u00f3n\n\n\nGcommit\n: invoca el comando \ngit commit\n abriendo una ventana de edici\u00f3n para poder escribir el mensaje del commit\n\n\nGpush\n: invoca el comando \ngit push\n\n\nGpull\n: invoca el comando \ngit pull\n\n\n\n\n\n\nMapeo de teclas\n\n\nMapeo de teclas del sistema en OSX\n\n\nEn muchos tutoriales sobre vim en OSX se recomienda mapear la tecla \nCaps Lock\n por \nEsc\n. El motivo es que la tecla \nEsc\n en el teclado del mac est\u00e1 muy lejos en la esquina superior izquierda, es muy peque\u00f1a y es una tecla muy usada en vim. AVISO: Este mapeo no se puede hacer dentro de vim, se tiene que hacer a nivel de sistema operativo. De esta forma, el mapeo afectar\u00e1 al funcionamiento de todo el sistema, no \u00fanicamente la aplicaci\u00f3n vim.\n\n\nNo tengo nada claro hacer este mapeo, precisamente porque afecta a todo el sistema, pero pongo a continuaci\u00f3n el programa para realizarlo, para referencia futura.\n\n\nEl programa para mapear la tecla \nCaps Lock\n es \nSeil\n. El mismo desarrollador tiene otra utilidad para hacer mapeos m\u00e1s generales de teclado llamada \nKarabiner\n.",
            "title": "Vim"
        },
        {
            "location": "/vim/#vim",
            "text": "",
            "title": "Vim"
        },
        {
            "location": "/vim/#documentacion-tutoriales-enlaces-libros",
            "text": "En  vimcasts.org  hay 68 tutoriales en video y 50 art\u00edculos sobre Vim. Realizados por Drew Neil, el autor del libro  Practical Vim .  El art\u00edculo  My experience with Vim  tiene una lista de plugins recomendados.",
            "title": "Documentaci\u00f3n, tutoriales, enlaces, libros"
        },
        {
            "location": "/vim/#libros",
            "text": "A Byte of Vim  es un libro sobre Vim (versi\u00f3n 7). Se puede leer online en la web del libro y tambi\u00e9n est\u00e1 disponible su descarga gratuita en formato ebook:  pdf ,  epub  y  mobi . El libro en formato  raw  est\u00e1 disponible en su  repositorio github .  Vim for humans  es un libro introductorio cuyo objetivo es simplificar la curva de aprendizaje cuando se empieza a usar Vim.",
            "title": "Libros"
        },
        {
            "location": "/vim/#vimrc",
            "text": "",
            "title": ".vimrc"
        },
        {
            "location": "/vim/#colores-esquemas-de-color",
            "text": "",
            "title": "Colores / Esquemas de color"
        },
        {
            "location": "/vim/#esquemas-de-color",
            "text": "Base16  Solarized  Gruvbox  Molokai  Badwolf  Wombat  Github",
            "title": "Esquemas de color"
        },
        {
            "location": "/vim/#base16",
            "text": "No es s\u00f3lo un esquema de colores, es un  framework  que proporciona un esquema de 16 colores (tiene una combinaci\u00f3n de 16 colores por defecto pero hay muchas combinaciones diferentes) y una configuraci\u00f3n para hacer  syntax highlighting  muy bien dise\u00f1ada.   La web principal del proyecto es  https://github.com/chriskempson/base16  Los diferentes temas creados con Base16 se pueden previsualizar en  https://chriskempson.github.io/base16/  Los temas Base16 para vim est\u00e1n en  https://github.com/chriskempson/base16-vim",
            "title": "Base16"
        },
        {
            "location": "/vim/#instalacion",
            "text": "A\u00f1adir lo siguiente al  vimrc  y ejecutar  PluginInstall  en Vim:  Plugin 'chriskempson/base16-vim'  Seleccionar el esquema de color deseado, por ejemplo:  colorscheme base16-default-dark  La lista de temas de color disponibles en Base16 est\u00e1 en https://github.com/chriskempson/base16-vim/tree/master/colors.  La p\u00e1gina de Base16 para vim tiene bastantes recetas para configurar Base16 para vim en modo terminal. Consultar tambi\u00e9n https://github.com/chriskempson/base16-iterm2 para informaci\u00f3n sobre colores Base16 para iTerm2 y https://github.com/chriskempson/base16-shell, que es una utilidad para configurar los colores del terminal.  [UPDATE: 02/08/17] : parece ser que hay emuladores de terminal en los que se puede cambiar la paleta de 256 colores, por ejemplo iTerm2. En el esquema de color Base16 se puede utilizar esta opci\u00f3n (cambiar la paleta de 256 colores) incluso se proporciona un  shell script  para cambiar los colores 17-21 de la paleta (para dejar los colores 0-15 sin cambiar y no afectar a otros programas) y versiones espec\u00edficas de los temas de color para esta configuraci\u00f3n. Hay m\u00e1s informaci\u00f3n sobre este tema en la p\u00e1gina  How to install base16 for iTerm2? .",
            "title": "Instalaci\u00f3n"
        },
        {
            "location": "/vim/#onedarkvim",
            "text": "onedark.vim  es un tema para vim inspirado en el excelente tema One Dark del editor Atom. El tema  base16-onedark  del esquema de colores Base16 est\u00e1 inspirado en este tema. Este tema tiene versiones para  true color  y para las paletas de 16 y 256 colores.  En la secci\u00f3n de instalaci\u00f3n de la p\u00e1gina del tema hay instrucciones para:   detectar si el terminal tiene soporte para  true color  configurar tmux para usar el tema  seleccionar las opciones de paleta de 16 y de 256 colores  configurar vim-airline  solucionar problemas comununes con  true color  y las paletas de 16 y 256 colores",
            "title": "onedark.vim"
        },
        {
            "location": "/vim/#true-color-en-el-terminal",
            "text": "",
            "title": "True Color en el terminal"
        },
        {
            "location": "/vim/#enlaces",
            "text": "Colours in terminal : un enlace a git con una explicaci\u00f3n muy buena sobre los diferentes modos de color de los emuladores de terminal, c\u00f3mo detectar si el emulador de terminal tiene soporte para  true color  y una lista de emuladores de terminal y programas con soporte para  true color  Support for True Color (16 millions colors) : otro enlace a git con explicaci\u00f3n de modos de color en los emuladores de terminal y soporte para  true color  en diferentes programas. Tiene enlaces a utilidades interesantes, como un programa que es capaz de mostrar una imagen en el emulador de terminar cuando tiene soporte para  true color  Using True Color in Vim with Tmux : una buena explicaci\u00f3n de los diferentes modos de color en los emuladores de terminal y un buen tutorial de c\u00f3mo activar el soporte para  true color  en vim y en  tmux   Los esquemas de color no se ven igual en versi\u00f3n  gui  que en terminal. Esto es porque en la versi\u00f3n  gui  vim utiliza todos los colores que proporciona el entorno gr\u00e1fico (utiliza  true color ) mientras que, por defecto, vim utiliza 256 colores en modo terminal, aunque el terminal tenga soporte para  true color .  El emulador de terminal tiene tres modos de color:   paleta de 16 colores  paleta de 256 colores  paleta de colores  true color   La paleta de 16 colores est\u00e1 formada por 8 colores est\u00e1ndar y 8 variantes \"brillantes\" de esos colores est\u00e1ndar. Los colores est\u00e1ndar son: negro, rojo, verde, amarillo, azul, magenta, cyan y blanco. El negro \"est\u00e1ndar\" es negro mientras que el negro \"brillante\" es un gris oscuro. El blanco \"est\u00e1ndar\" es un gris claro mientras que el blanco \"brillante\" es blanco. Muchos programas de terminal asumen esta disposici\u00f3n de colores. La paleta de 16 colores s\u00ed que se puede cambiar por lo que, en teor\u00eda, se pueden configurar esos 16 colores para que sean iguales a los de la paleta del esquema de color. Lo que ocurre es que es muy probable que los colores que quedan bien en vim en cuanto se sale de vim y se ejecuta otro programa (por ejemplo tmux) ya se vean mal. El motivo es que el otro programa no tiene forma de saber que se ha cambiado la paleta de 16 colores y da por sentado que se est\u00e1 usando la paleta est\u00e1ndar de 16 colores. Por este motivo, no suele usarse esta opci\u00f3n (cambiar la paleta de 16 colores) para cambiar los colores de vim en modo terminal.  La paleta de 256 colores es fija, no se puede cambiar. Algunos esquemas de color tienen una versi\u00f3n de 256 colores, en la que utilizan los colores fijos m\u00e1s parecidos posible a los colores  true color  originales de la paleta. Esta es la opci\u00f3n m\u00e1s utilizada para cambiar los colores de vim en modo terminal, porque no se modifica la paleta de 16 colores y los otros programas de terminal no se ven afectados.  [UPDATE: 02/08/17] : parece ser que hay emuladores de terminal en los que se puede cambiar la paleta de 256 colores, por ejemplo iTerm2. En el esquema de color Base16 se puede utilizar esta opci\u00f3n (cambiar la paleta de 256 colores) incluso se proporciona un  shell script  para cambiar los colores 17-21 de la paleta (para dejar los colores 0-15 sin cambiar y no afectar a otros programas) y versiones espec\u00edficas de los temas de color para esta configuraci\u00f3n.  Cuando el emulador de terminal tiene soporte para  true color  est\u00e1n disponibles 32 millones de colores (colores de 24 bits) por lo que cualquier paleta de colores de cualquier programa se ve perfectamente. Es exactamente igual que lo que pasa cuando se utiliza un escritorio gr\u00e1fico (Mac, Windows, etc). Esta es la opci\u00f3n recomendada.  Para saber si un emulador de terminal tiene soporte para  true color  o no, el siguiente comando:  $ printf \"\\x1b[38;2;255;100;0mTRUECOLOR\\x1b[0m\\n\"  debe escribir la palabra TRUECOLOR en color rojo en un emulador de terminal con soporte para  true color . Tambi\u00e9n se puede ejecutar el siguiente comando  awk , que en un terminar con soporte para  true color  debe mostrar un degradado de colores cont\u00ednuo:  $ awk 'BEGIN{\n    s=\"/\\\\/\\\\/\\\\/\\\\/\\\\\"; s=s s s s s s s s;\n    for (colnum = 0; colnum<77; colnum++) {\n        r = 255-(colnum*255/76);\n        g = (colnum*510/76);\n        b = (colnum*255/76);\n        if (g>255) g = 510-g;\n        printf \"\\033[48;2;%d;%d;%dm\", r,g,b;\n        printf \"\\033[38;2;%d;%d;%dm\", 255-r,255-g,255-b;\n        printf \"%s\\033[0m\", substr(s,colnum+1,1);\n    }\n    printf \"\\n\";\n}'  Para que vim utilice  true colors  en modo terminal hay que a\u00f1adir  set termguicolors  en  .vimrc . Los terminales  mintty  (Cygwin),  iTerm2  (Mac) y  gnuterm  (Linux) tienen soporte para  true color .  [UPDATE: 12/07/2017]  Hay un problema con el  colorscheme   Solarized  en modo terminal con el  true color  activado. Los colores salen totalmente cambiados, tanto con el background light como dark.",
            "title": "Enlaces"
        },
        {
            "location": "/vim/#plugin-managers",
            "text": "",
            "title": "Plugin managers"
        },
        {
            "location": "/vim/#vundle",
            "text": "Vundle  es un verdadero  plugin manager , en el sentido de que, a partir de la configuraci\u00f3n que se hace en el archivo  .vimrc , descarga autom\u00e1ticamente los plugins y tiene comandos para actualizar la versi\u00f3n de los plugins instalados, etc. Es m\u00e1s completo que  Pathogen  en cuanto a funcionalidad.",
            "title": "Vundle"
        },
        {
            "location": "/vim/#instalacion_1",
            "text": "",
            "title": "Instalaci\u00f3n"
        },
        {
            "location": "/vim/#uso",
            "text": "",
            "title": "Uso"
        },
        {
            "location": "/vim/#pathogen",
            "text": "",
            "title": "Pathogen"
        },
        {
            "location": "/vim/#instalacion_2",
            "text": "",
            "title": "Instalaci\u00f3n"
        },
        {
            "location": "/vim/#uso_1",
            "text": "",
            "title": "Uso"
        },
        {
            "location": "/vim/#plugins",
            "text": "",
            "title": "Plugins"
        },
        {
            "location": "/vim/#fugitive",
            "text": "Fugitive  es un recubrimiento del comando git.",
            "title": "Fugitive"
        },
        {
            "location": "/vim/#tutoriales-documentacion",
            "text": "Hay una serie de 5 tutoriales en video en  vimcasts.org . El primero de ellos es este:  Fugitive.vim - a complement to command line git",
            "title": "Tutoriales, documentaci\u00f3n"
        },
        {
            "location": "/vim/#instalacion_3",
            "text": "En la secci\u00f3n de  Vundle  de  .vimrc , a\u00f1adir:  Plugin 'tpope/vim-fugitive'",
            "title": "Instalaci\u00f3n"
        },
        {
            "location": "/vim/#uso_2",
            "text": "Los comandos de Fugitive empiezan con G (g may\u00fascula). Se utilizan en modo vim normal, tecleando los dos puntos (:). Los comandos m\u00e1s habituales son:   Gwrite : guarda el archivo e invoca el commando  git add  Gread : descarta los cambios del archivo que se est\u00e1 editando y recupera la \u00faltima versi\u00f3n guardada en git. Una vez recuperada, vuelve a abrirla en el buffer de edici\u00f3n  Gcommit : invoca el comando  git commit  abriendo una ventana de edici\u00f3n para poder escribir el mensaje del commit  Gpush : invoca el comando  git push  Gpull : invoca el comando  git pull",
            "title": "Uso"
        },
        {
            "location": "/vim/#mapeo-de-teclas",
            "text": "",
            "title": "Mapeo de teclas"
        },
        {
            "location": "/vim/#mapeo-de-teclas-del-sistema-en-osx",
            "text": "En muchos tutoriales sobre vim en OSX se recomienda mapear la tecla  Caps Lock  por  Esc . El motivo es que la tecla  Esc  en el teclado del mac est\u00e1 muy lejos en la esquina superior izquierda, es muy peque\u00f1a y es una tecla muy usada en vim. AVISO: Este mapeo no se puede hacer dentro de vim, se tiene que hacer a nivel de sistema operativo. De esta forma, el mapeo afectar\u00e1 al funcionamiento de todo el sistema, no \u00fanicamente la aplicaci\u00f3n vim.  No tengo nada claro hacer este mapeo, precisamente porque afecta a todo el sistema, pero pongo a continuaci\u00f3n el programa para realizarlo, para referencia futura.  El programa para mapear la tecla  Caps Lock  es  Seil . El mismo desarrollador tiene otra utilidad para hacer mapeos m\u00e1s generales de teclado llamada  Karabiner .",
            "title": "Mapeo de teclas del sistema en OSX"
        },
        {
            "location": "/git/",
            "text": "Guia r\u00e1pida de git\n\n\n\n\nEnlaces, documentaci\u00f3n\n\n\n\n\nEmpezar a usar git en un ordenador nuevo\n\n\nPara empezar a utilizar git en un nuevo ordenador, hay que realizar dos tareas:\n\n\n\n\nConfigurar git en el nuevo ordenador\n\n\nCrear y configurar la clave ssh para conectarse a github.com desde el nuevo ordenador\n\n\n\n\nConfigurar git en un nuevo ordenador\n\n\nAntes de crear un repositorio nuevo, o clonar uno existente, despu\u00e9s de instalar el software de git, hay que configurar el usuario, tanto el \nusername\n como el \nemail\n.\n\n\nConfigurar el \nusername\n. La opci\u00f3n \n--global\n es para que la opci\u00f3n aplique de forma global a todos los repositorios:\n\n\n$ git config --global user.name \"Alvaro Sainz-Pardo\"\n\n\n\n\nConsultar el valor de la variable \nuser.name\n:\n\n\n$ git config --global user.name\n\n\n\n\nConfigurar el email:\n\n\n$ git config --global user.email \"alvarosainzpardo@gmail.com\"\n\n\n\n\nConsultar el valor de la variable \nuser.email\n:\n\n\n$ git config --global user.email\n\n\n\n\nPara borrar el valor de una variable se utiliza la opci\u00f3n \n--unset\n:\n\n\n$ git config --global --unset user.name\n$ git config --global --unset user.email\n\n\n\n\nCrear y configurar la clave ssh para conectarse a GitHub\n\n\nHay dos tipos de URLs que se pueden utilizar para referenciar los repositorios remotos en GitHub: http y ssh.\n\n\nSi se utilizan urls de tipo ssh, los pasos que hay que dar para autorizar la conexi\u00f3n a GitHub desde un ordenador nuevo son:\n\n\n\n\nCrear la clave en el ordenador nuevo\n\n\nImportar la clave en la cuenta de github.com\n\n\nProbar la conexi\u00f3n\n\n\n\n\nCrear la clave en el ordenador nuevo\n\n\nCrear la clave con el siguiente comando, poniendo la direcci\u00f3n de correo de la cuenta en github.com:\n\n\n$ ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n\n\n\n\nCuando pregunte por la localizaci\u00f3n del archivo, pulsar Enter:\n\n\nEnter a file in which to save the key (/home/you/.ssh/id_rsa): [Press enter]\n\n\n\n\nCuando pregunte por la \npassphrase\n, teclear una \npassphrase\n o pulsar Enter:\n\n\nEnter passphrase (empty for no passphrase): [Type a passphrase]\nEnter same passphrase again: [Type passphrase again]\n\n\n\n\nImportar la clave en la cuenta de github.com\n\n\nSeguir las instrucciones de \nAdding a new SSH key to your GitHub account\n.\n\n\nProbar la conexi\u00f3n\n\n\nPara probar que la nueva conexi\u00f3n funciona se utiliza el siguiente comando:\n\n\n$ ssh -T git@github.com\n\n\n\n\nSi hay errores de conexi\u00f3n, seguir las instrucciones de \nError: Permission denied (publickey)\n.\n\n\n\n\nAcceso mediante http\n\n\nSi se utiliza http, no hay que crear claves de ssh ni darlas de alta en la cuenta de GitHub, simplemente hay que usar la url de tipo http al clonar el repositorio remoto. Por ejemplo:\n\n\n$ git clone https://github.com/alvarosainzpardo/dotfiles.git\n\n\n\n\nEste m\u00e9todo de conexi\u00f3n funciona tambi\u00e9n si se est\u00e1 detr\u00e1s de un proxy (ver instrucciones). La desventaja es que se pregunta el usuario y la clave de GitHub cada vez que se utiliza un comando git. Para evitar que esto ocurra, se puede utilizar un \ncredential helper\n que cachea el usuario/password durante un tiempo determinado.\n\n\nPara activar el \ncredential helper\n:\n\n\n$ git config --global credential.helper cache\n# Set git to use the credential memory cache\n\n\n\n\nPara cambiar el tiempo predeterminado de cacheo de 15 minutos:\n\n\n$ git config --global credential.helper 'cache --timeout=3600'\n# Set the cache to timeout after 1 hour (setting is in seconds)\n\n\n\n\n\n\nConfigurar git detr\u00e1s de un proxy\n\n\nSi te conectas a github.com mediante http, lo que hay que hacer es configurar la variable \nhttp.proxy\n con el valor correspondiente al proxy de la red:\n\n\n$ git config --global http.proxy http://<user>:<passwd>@<proxyserver>:<port>/\n\n\n\n\nTambi\u00e9n la variable \nhttps.proxy\n:\n\n\n$ git config --global https.proxy http://<user>:<passwd>@<proxyserver>:<port>/\n\n\n\n\nPor ejemplo:\n\n\n$ git config --global http.proxy http://ds01170:<passwd>@proxyinternet.tesa:8080/\n$ git config --global https.proxy http://ds01170:<passwd>@proxyinternet.tesa:8080/\n\n\n\n\nPara eliminar el valor de las variables para el proxy, se utiliza la opci\u00f3n \n--unset\n:\n\n\n$ git config --global --unset http.proxy\n$ git config --global --unset https.proxy\n\n\n\n\nSi la conexi\u00f3n a github.com es mediante ssh, cuando se accede detr\u00e1s de un proxy hay que \nconfigurar el ssh para que utilice un proxy\n para las conexiones.",
            "title": "Git"
        },
        {
            "location": "/git/#guia-rapida-de-git",
            "text": "",
            "title": "Guia r\u00e1pida de git"
        },
        {
            "location": "/git/#enlaces-documentacion",
            "text": "",
            "title": "Enlaces, documentaci\u00f3n"
        },
        {
            "location": "/git/#empezar-a-usar-git-en-un-ordenador-nuevo",
            "text": "Para empezar a utilizar git en un nuevo ordenador, hay que realizar dos tareas:   Configurar git en el nuevo ordenador  Crear y configurar la clave ssh para conectarse a github.com desde el nuevo ordenador",
            "title": "Empezar a usar git en un ordenador nuevo"
        },
        {
            "location": "/git/#configurar-git-en-un-nuevo-ordenador",
            "text": "Antes de crear un repositorio nuevo, o clonar uno existente, despu\u00e9s de instalar el software de git, hay que configurar el usuario, tanto el  username  como el  email .  Configurar el  username . La opci\u00f3n  --global  es para que la opci\u00f3n aplique de forma global a todos los repositorios:  $ git config --global user.name \"Alvaro Sainz-Pardo\"  Consultar el valor de la variable  user.name :  $ git config --global user.name  Configurar el email:  $ git config --global user.email \"alvarosainzpardo@gmail.com\"  Consultar el valor de la variable  user.email :  $ git config --global user.email  Para borrar el valor de una variable se utiliza la opci\u00f3n  --unset :  $ git config --global --unset user.name\n$ git config --global --unset user.email",
            "title": "Configurar git en un nuevo ordenador"
        },
        {
            "location": "/git/#crear-y-configurar-la-clave-ssh-para-conectarse-a-github",
            "text": "Hay dos tipos de URLs que se pueden utilizar para referenciar los repositorios remotos en GitHub: http y ssh.  Si se utilizan urls de tipo ssh, los pasos que hay que dar para autorizar la conexi\u00f3n a GitHub desde un ordenador nuevo son:   Crear la clave en el ordenador nuevo  Importar la clave en la cuenta de github.com  Probar la conexi\u00f3n",
            "title": "Crear y configurar la clave ssh para conectarse a GitHub"
        },
        {
            "location": "/git/#crear-la-clave-en-el-ordenador-nuevo",
            "text": "Crear la clave con el siguiente comando, poniendo la direcci\u00f3n de correo de la cuenta en github.com:  $ ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"  Cuando pregunte por la localizaci\u00f3n del archivo, pulsar Enter:  Enter a file in which to save the key (/home/you/.ssh/id_rsa): [Press enter]  Cuando pregunte por la  passphrase , teclear una  passphrase  o pulsar Enter:  Enter passphrase (empty for no passphrase): [Type a passphrase]\nEnter same passphrase again: [Type passphrase again]",
            "title": "Crear la clave en el ordenador nuevo"
        },
        {
            "location": "/git/#importar-la-clave-en-la-cuenta-de-githubcom",
            "text": "Seguir las instrucciones de  Adding a new SSH key to your GitHub account .",
            "title": "Importar la clave en la cuenta de github.com"
        },
        {
            "location": "/git/#probar-la-conexion",
            "text": "Para probar que la nueva conexi\u00f3n funciona se utiliza el siguiente comando:  $ ssh -T git@github.com  Si hay errores de conexi\u00f3n, seguir las instrucciones de  Error: Permission denied (publickey) .",
            "title": "Probar la conexi\u00f3n"
        },
        {
            "location": "/git/#acceso-mediante-http",
            "text": "Si se utiliza http, no hay que crear claves de ssh ni darlas de alta en la cuenta de GitHub, simplemente hay que usar la url de tipo http al clonar el repositorio remoto. Por ejemplo:  $ git clone https://github.com/alvarosainzpardo/dotfiles.git  Este m\u00e9todo de conexi\u00f3n funciona tambi\u00e9n si se est\u00e1 detr\u00e1s de un proxy (ver instrucciones). La desventaja es que se pregunta el usuario y la clave de GitHub cada vez que se utiliza un comando git. Para evitar que esto ocurra, se puede utilizar un  credential helper  que cachea el usuario/password durante un tiempo determinado.  Para activar el  credential helper :  $ git config --global credential.helper cache\n# Set git to use the credential memory cache  Para cambiar el tiempo predeterminado de cacheo de 15 minutos:  $ git config --global credential.helper 'cache --timeout=3600'\n# Set the cache to timeout after 1 hour (setting is in seconds)",
            "title": "Acceso mediante http"
        },
        {
            "location": "/git/#configurar-git-detras-de-un-proxy",
            "text": "Si te conectas a github.com mediante http, lo que hay que hacer es configurar la variable  http.proxy  con el valor correspondiente al proxy de la red:  $ git config --global http.proxy http://<user>:<passwd>@<proxyserver>:<port>/  Tambi\u00e9n la variable  https.proxy :  $ git config --global https.proxy http://<user>:<passwd>@<proxyserver>:<port>/  Por ejemplo:  $ git config --global http.proxy http://ds01170:<passwd>@proxyinternet.tesa:8080/\n$ git config --global https.proxy http://ds01170:<passwd>@proxyinternet.tesa:8080/  Para eliminar el valor de las variables para el proxy, se utiliza la opci\u00f3n  --unset :  $ git config --global --unset http.proxy\n$ git config --global --unset https.proxy  Si la conexi\u00f3n a github.com es mediante ssh, cuando se accede detr\u00e1s de un proxy hay que  configurar el ssh para que utilice un proxy  para las conexiones.",
            "title": "Configurar git detr\u00e1s de un proxy"
        },
        {
            "location": "/markdown/",
            "text": "Referencia r\u00e1pida de Markdown\n\n\n\n\nEnlaces\n\n\nHay buenos tutoriales de Markdown en:\n\n\n\n\nMarkdown Cheatsheet\n\n\nMastering Markdown\n\n\n\n\n\n\nCabeceras\n\n\n# H1\n## H2\n### H3\n#### H4\n##### H5\n###### H6\n\n\n\n\nH1\n\n\nH2\n\n\nH3\n\n\nH4\n\n\nH5\n\n\nH6\n\n\n\n\nP\u00e1rrafos\n\n\n\nPara empezar un p\u00e1rrafo nuevo, se deja arriba una l\u00ednea en blanco. En otros elementos de Markdown (listas, l\u00edneas de separaci\u00f3n) tambi\u00e9n hay que poner una l\u00ednea en blanco encima.\n\nEste es otro p\u00e1rrafo.\nEsta es una l\u00ednea nueva sin dejar una l\u00ednea en blanco antes, esta l\u00ednea va a ir a continuaci\u00f3n de la anterior, como si no hubiese habido un salto de l\u00ednea.\n\nSi se quiere hacer un salto de l\u00ednea sin empezar un nuevo p\u00e1rrafo, se dejan dos espacios en blanco al final de la l\u00ednea anterior.  \nUna nueva l\u00ednea en el mismo p\u00e1rrafo.\n\n\n\n\nPara empezar un p\u00e1rrafo nuevo, se deja arriba una l\u00ednea en blanco. En otros elementos de Markdown (listas, l\u00edneas de separaci\u00f3n) tambi\u00e9n hay que poner una l\u00ednea en blanco encima.\n\n\nEste es otro p\u00e1rrafo.\nEsta es una l\u00ednea nueva sin dejar una l\u00ednea en blanco antes, esta l\u00ednea va a ir a continuaci\u00f3n de la anterior, como si no hubiese habido un salto de l\u00ednea.\n\n\nSi se quiere hacer un salto de l\u00ednea sin empezar un nuevo p\u00e1rrafo, se dejan dos espacios en blanco al final de la l\u00ednea anterior.\n\nUna nueva l\u00ednea en el mismo p\u00e1rrafo.\n\n\n\n\n\u00c9nfasis\n\n\nEl texto en *it\u00e1lica*, con *asteriscos* o _guiones bajos_.\n\nEl texto en **negrita**, con **dos asteriscos** o __dos guiones bajos__.\n\nSe puede combinar la **negrita** y la _it\u00e1lica_, con **asteriscos y _guiones bajos_**.\n\nEl texto tachado, con ~~dos tildes~~.\n\n\n\n\nEl texto en \nit\u00e1lica\n, con \nasteriscos\n o \nguiones bajos\n.\n\n\nEl texto en \nnegrita\n, con \ndos asteriscos\n o \ndos guiones bajos\n.\n\n\nSe puede combinar la \nnegrita\n y la \nit\u00e1lica\n, con \nasteriscos y \nguiones bajos\n.\n\n\nEl texto tachado, con ~~dos tildes~~.\n\n\n\n\nListas",
            "title": "Markdown"
        },
        {
            "location": "/markdown/#referencia-rapida-de-markdown",
            "text": "",
            "title": "Referencia r\u00e1pida de Markdown"
        },
        {
            "location": "/markdown/#enlaces",
            "text": "Hay buenos tutoriales de Markdown en:   Markdown Cheatsheet  Mastering Markdown",
            "title": "Enlaces"
        },
        {
            "location": "/markdown/#cabeceras",
            "text": "# H1\n## H2\n### H3\n#### H4\n##### H5\n###### H6",
            "title": "Cabeceras"
        },
        {
            "location": "/markdown/#h1",
            "text": "",
            "title": "H1"
        },
        {
            "location": "/markdown/#h2",
            "text": "",
            "title": "H2"
        },
        {
            "location": "/markdown/#h3",
            "text": "",
            "title": "H3"
        },
        {
            "location": "/markdown/#h4",
            "text": "",
            "title": "H4"
        },
        {
            "location": "/markdown/#h5",
            "text": "",
            "title": "H5"
        },
        {
            "location": "/markdown/#h6",
            "text": "",
            "title": "H6"
        },
        {
            "location": "/markdown/#parrafos",
            "text": "Para empezar un p\u00e1rrafo nuevo, se deja arriba una l\u00ednea en blanco. En otros elementos de Markdown (listas, l\u00edneas de separaci\u00f3n) tambi\u00e9n hay que poner una l\u00ednea en blanco encima.\n\nEste es otro p\u00e1rrafo.\nEsta es una l\u00ednea nueva sin dejar una l\u00ednea en blanco antes, esta l\u00ednea va a ir a continuaci\u00f3n de la anterior, como si no hubiese habido un salto de l\u00ednea.\n\nSi se quiere hacer un salto de l\u00ednea sin empezar un nuevo p\u00e1rrafo, se dejan dos espacios en blanco al final de la l\u00ednea anterior.  \nUna nueva l\u00ednea en el mismo p\u00e1rrafo.  Para empezar un p\u00e1rrafo nuevo, se deja arriba una l\u00ednea en blanco. En otros elementos de Markdown (listas, l\u00edneas de separaci\u00f3n) tambi\u00e9n hay que poner una l\u00ednea en blanco encima.  Este es otro p\u00e1rrafo.\nEsta es una l\u00ednea nueva sin dejar una l\u00ednea en blanco antes, esta l\u00ednea va a ir a continuaci\u00f3n de la anterior, como si no hubiese habido un salto de l\u00ednea.  Si se quiere hacer un salto de l\u00ednea sin empezar un nuevo p\u00e1rrafo, se dejan dos espacios en blanco al final de la l\u00ednea anterior. \nUna nueva l\u00ednea en el mismo p\u00e1rrafo.",
            "title": "P\u00e1rrafos"
        },
        {
            "location": "/markdown/#enfasis",
            "text": "El texto en *it\u00e1lica*, con *asteriscos* o _guiones bajos_.\n\nEl texto en **negrita**, con **dos asteriscos** o __dos guiones bajos__.\n\nSe puede combinar la **negrita** y la _it\u00e1lica_, con **asteriscos y _guiones bajos_**.\n\nEl texto tachado, con ~~dos tildes~~.  El texto en  it\u00e1lica , con  asteriscos  o  guiones bajos .  El texto en  negrita , con  dos asteriscos  o  dos guiones bajos .  Se puede combinar la  negrita  y la  it\u00e1lica , con  asteriscos y  guiones bajos .  El texto tachado, con ~~dos tildes~~.",
            "title": "\u00c9nfasis"
        },
        {
            "location": "/markdown/#listas",
            "text": "",
            "title": "Listas"
        },
        {
            "location": "/brew/",
            "text": "Homebrew\n\n\n\n\nComandos\n\n\nActualizar la versi\u00f3n de brew y la informaci\u00f3n de paquetes\n\n\n$ brew update\n\n\n\n\nActualizar los paquetes instalados\n\n\n$ brew upgrade",
            "title": "Homebrew"
        },
        {
            "location": "/brew/#homebrew",
            "text": "",
            "title": "Homebrew"
        },
        {
            "location": "/brew/#comandos",
            "text": "Actualizar la versi\u00f3n de brew y la informaci\u00f3n de paquetes  $ brew update  Actualizar los paquetes instalados  $ brew upgrade",
            "title": "Comandos"
        },
        {
            "location": "/robocopy/",
            "text": "Guia del comando \nrobocopy\n\n\n\n\nEnlaces, documentaci\u00f3n\n\n\n\n\nRobocopy\n\n\nRobocopy and a Few Examples\n\n\nComo usar el comando Robocopy en Windows, ejemplos pr\u00e1cticos y c\u00f3digos\n\n\n\n\n\n\nComando para hacer backup de los contenidos de un directorio\n\n\nC:\\>robocopy <origen> <destino> /mir /sl /xjd /xa:sh /xd \"AppData\" /xf *.inf /copy:dat /dcopy:t /r:0 /w:1 /mt /ndl /tee /log+:\\robocopy.log\n\n\n\n\nExplicaci\u00f3n de las opciones\n\n\n\n\n/mir\n: realiza una copia exacta o espejo del directorio origen en el directorio destino. Si en el directorio origen se han borrado archivos, se eliminar\u00e1n en el directorio destino\n\n\n/sl\n: copia los enlaces simb\u00f3licos como enlaces simb\u00f3licos en el destino\n\n\n/xjd\n: excluye \njunction points\n en este caso directorios. Otras opciones pueden ser \n/xjf\npara excluir \njunction points\n de archivos y \n/xj\npara excluir todos los \njuntion points\n, tanto archivos como directorios\n\n\n/xa:sh\n: excluye archivos de sistema (s) y ocultos (h)\n\n\n/xd \"AppData\"\n: excluye los (sub)directorios llamados \nAppData\n\n\n/xf *.inf\n: excluye los archivos .inf\n\n\n/copy:dat\n: copia los datos, atributos y \ntimestamp\n de los archivos origen\n\n\n/dcopy:t\n: copia, o mantiene, el \ntimestamp\n de los directorios origen\n\n\n/r:0\n: no realiza ning\u00fan reintento si se produce un error\n\n\n/w:1\n: tiempo de espera transcurrido entre reintentos (aplicable cuando /r tiene valor mayor que 0)\n\n\n/mt\n: utiliza \nmultithreading\n cuando la cpu tiene varios n\u00facleos\n\n\n/ndl\n: sin lista de directorios, no registra los nombres de directorio\n\n\n/tee\n: copia la salida est\u00e1ndar del comando en el archivo de log\n\n\n/log+:<archivo.log>: realiza un log en el archivo especificado, la opci\u00f3n\n+` sirve para a\u00f1adir el contenido del log si el archivo ya existe (append)",
            "title": "Robocopy"
        },
        {
            "location": "/robocopy/#guia-del-comando-robocopy",
            "text": "",
            "title": "Guia del comando robocopy"
        },
        {
            "location": "/robocopy/#enlaces-documentacion",
            "text": "Robocopy  Robocopy and a Few Examples  Como usar el comando Robocopy en Windows, ejemplos pr\u00e1cticos y c\u00f3digos",
            "title": "Enlaces, documentaci\u00f3n"
        },
        {
            "location": "/robocopy/#comando-para-hacer-backup-de-los-contenidos-de-un-directorio",
            "text": "C:\\>robocopy <origen> <destino> /mir /sl /xjd /xa:sh /xd \"AppData\" /xf *.inf /copy:dat /dcopy:t /r:0 /w:1 /mt /ndl /tee /log+:\\robocopy.log",
            "title": "Comando para hacer backup de los contenidos de un directorio"
        },
        {
            "location": "/robocopy/#explicacion-de-las-opciones",
            "text": "/mir : realiza una copia exacta o espejo del directorio origen en el directorio destino. Si en el directorio origen se han borrado archivos, se eliminar\u00e1n en el directorio destino  /sl : copia los enlaces simb\u00f3licos como enlaces simb\u00f3licos en el destino  /xjd : excluye  junction points  en este caso directorios. Otras opciones pueden ser  /xjf para excluir  junction points  de archivos y  /xj para excluir todos los  juntion points , tanto archivos como directorios  /xa:sh : excluye archivos de sistema (s) y ocultos (h)  /xd \"AppData\" : excluye los (sub)directorios llamados  AppData  /xf *.inf : excluye los archivos .inf  /copy:dat : copia los datos, atributos y  timestamp  de los archivos origen  /dcopy:t : copia, o mantiene, el  timestamp  de los directorios origen  /r:0 : no realiza ning\u00fan reintento si se produce un error  /w:1 : tiempo de espera transcurrido entre reintentos (aplicable cuando /r tiene valor mayor que 0)  /mt : utiliza  multithreading  cuando la cpu tiene varios n\u00facleos  /ndl : sin lista de directorios, no registra los nombres de directorio  /tee : copia la salida est\u00e1ndar del comando en el archivo de log  /log+:<archivo.log>: realiza un log en el archivo especificado, la opci\u00f3n +` sirve para a\u00f1adir el contenido del log si el archivo ya existe (append)",
            "title": "Explicaci\u00f3n de las opciones"
        },
        {
            "location": "/lossless/",
            "text": "Archivos de audio \nlossless\n\n\n\n\nEnlaces, documentaci\u00f3n\n\n\n\n\nHow To tell between a 'real' FLAC and a 'fake' FLAC?\n\n\nHow To tell between a 'real' FLAC and a 'fake' FLAC?\n\n\nSpectral Analysis\n\n\nTranscode Spectral Study - A Primer on Spectral Analysis and How to Spot Transcodes\n\n\n\n\n\n\nSoftware para detectar si un archivo FLAC es autentico o no\n\n\nTAU - AuCDtect\n\n\nTrue Audio Checker - Project Description\n\n\nEs un programa que realiza un test autom\u00e1tico para comprobar si un archivo FLAC, APE, etc es aut\u00e9ntico o no. El software es para Windows, con varias opciones de descarga y hay un plugin para Foobar2000.\n\n\nLossless Audio Checker\n\n\nLossless Audio Checker\n\n\nEs otro programa que hace test autom\u00e1ticos para determinar la autenticidad de un archivo FLAC. Tiene un cliente gr\u00e1fico solo para Windows y una utilidad de linea de comandos para varios sistemas operativos, incluido Mac, que solo analiza archivos WAV (antes hay que convertir el FLAC en WAV).\n\n\nSpek\n\n\nSpek \u2013 Acoustic Spectrum Analyser\n\n\nEs un analizador de espectro multiformato, tambi\u00e9n disponible para Mac.\n\n\nAudacity\n\n\nTambi\u00e9n permite hacer an\u00e1lisis del espectro del archivo. En este \nvideo\n hay un buen tutorial.",
            "title": "Lossless"
        },
        {
            "location": "/lossless/#archivos-de-audio-lossless",
            "text": "",
            "title": "Archivos de audio lossless"
        },
        {
            "location": "/lossless/#enlaces-documentacion",
            "text": "How To tell between a 'real' FLAC and a 'fake' FLAC?  How To tell between a 'real' FLAC and a 'fake' FLAC?  Spectral Analysis  Transcode Spectral Study - A Primer on Spectral Analysis and How to Spot Transcodes",
            "title": "Enlaces, documentaci\u00f3n"
        },
        {
            "location": "/lossless/#software-para-detectar-si-un-archivo-flac-es-autentico-o-no",
            "text": "",
            "title": "Software para detectar si un archivo FLAC es autentico o no"
        },
        {
            "location": "/lossless/#tau-aucdtect",
            "text": "True Audio Checker - Project Description  Es un programa que realiza un test autom\u00e1tico para comprobar si un archivo FLAC, APE, etc es aut\u00e9ntico o no. El software es para Windows, con varias opciones de descarga y hay un plugin para Foobar2000.",
            "title": "TAU - AuCDtect"
        },
        {
            "location": "/lossless/#lossless-audio-checker",
            "text": "Lossless Audio Checker  Es otro programa que hace test autom\u00e1ticos para determinar la autenticidad de un archivo FLAC. Tiene un cliente gr\u00e1fico solo para Windows y una utilidad de linea de comandos para varios sistemas operativos, incluido Mac, que solo analiza archivos WAV (antes hay que convertir el FLAC en WAV).",
            "title": "Lossless Audio Checker"
        },
        {
            "location": "/lossless/#spek",
            "text": "Spek \u2013 Acoustic Spectrum Analyser  Es un analizador de espectro multiformato, tambi\u00e9n disponible para Mac.",
            "title": "Spek"
        },
        {
            "location": "/lossless/#audacity",
            "text": "Tambi\u00e9n permite hacer an\u00e1lisis del espectro del archivo. En este  video  hay un buen tutorial.",
            "title": "Audacity"
        }
    ]
}